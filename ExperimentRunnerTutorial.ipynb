{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/HamidrezaKmK/ML-Mnemonist/blob/main/ExperimentRunnerTutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rE6olttuFV0Q"
   },
   "source": [
    "# Setup hosted runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eOfp_NGbT1jZ",
    "outputId": "79649df5-19a7-4f4a-a2a6-f49a6cc498c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing sys_setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile sys_setup.py\n",
    "#!usr/bin/bash python\n",
    "\n",
    "import sys\n",
    "from google.colab import drive\n",
    "import subprocess\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "PROJ_NAME = 'ML-Mnemonist'\n",
    "GIT_DIR = 'HamidrezaKmK'\n",
    "\n",
    "data_dir = None\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  env = os.environ.copy()\n",
    "  if not os.path.exists('/content/drive'):\n",
    "    print(\"Mounting drive...\")\n",
    "    drive.mount('/content/drive')\n",
    "    print(\"Mount complete!\")\n",
    "\n",
    "  while True:\n",
    "    opt = input(\"What are you trying to do? [clone/pull] \")\n",
    "    if opt == 'clone':\n",
    "      addr = f\"https://github.com/{GIT_DIR}/{PROJ_NAME}\"\n",
    "      print(f\"Trying to connect to {addr}\")\n",
    "      token = input(\"Enter token: \")\n",
    "      addr = addr.replace('[TOKEN]', token)\n",
    "      res = subprocess.run(['git', 'clone', addr], env=env, capture_output=True)\n",
    "      print(res.stdout.decode())\n",
    "      print(res.stderr.decode())\n",
    "      break\n",
    "    elif opt == 'pull':\n",
    "      path = os.path.join('/content', PROJ_NAME)\n",
    "      os.chdir(path)\n",
    "      res = subprocess.run(['git', 'pull'], env=env, capture_output=True)\n",
    "      print(res.stdout.decode())\n",
    "      print(res.stderr.decode())\n",
    "      break\n",
    "    elif opt == '':\n",
    "      print(\"Nothing happened!\")\n",
    "      break\n",
    "  \n",
    "  if not os.path.exists(f'/content/{PROJ_NAME}'):\n",
    "    raise RuntimeError(\"No project repository available!\")\n",
    "\n",
    "  if not os.path.exists(f'/content/{PROJ_NAME}/.env'):\n",
    "    print(\"Dotenv non-existant!\")\n",
    "    while True:\n",
    "      resp = input(\"Do you want to enter the file in the prompt or copy it?\\n[copy/write] \")\n",
    "      if resp == 'copy':\n",
    "        dir = input(\"Enter the directory to copy: \")\n",
    "        shutil.copyfile(dir, f'/content/{PROJ_NAME}/.env')\n",
    "      elif resp == 'write':\n",
    "        print(\"Enter the lines in format ENV_VARIABLE_NAME=VALUE\")\n",
    "        print(\"End with: ENDFILE\")\n",
    "        with open(f'/content/{PROJ_NAME}/.env', 'w') as f:\n",
    "          while True:\n",
    "            line = input()\n",
    "            if line == 'ENDFILE':\n",
    "              break\n",
    "            f.write(f'{line}\\n')\n",
    "      else:\n",
    "        continue\n",
    "      break\n",
    "        \n",
    "  os.chdir('/content')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "mzkBQqSLUWC3",
    "outputId": "2d475291-ff6f-430d-da51-06a1eb22bb66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running complete!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PROJ_NAME = 'ML-Mnemonist'\n",
    "\n",
    "from IPython.display import clear_output\n",
    "%run /content/sys_setup.py\n",
    "resp = input(\"Do you want to install packages? [y/n] \")\n",
    "if resp == 'y':\n",
    "  !pip install -r /content/ML-Mnemonist/requirements.txt\n",
    "  input(\"Requrements installed! -- press any key to continue ...\")\n",
    "clear_output()\n",
    "\n",
    "import sys\n",
    "sys.path.append(f'/content/{PROJ_NAME}')\n",
    "os.chdir(f'/content/{PROJ_NAME}')\n",
    "print(\"Running complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iNiIuYQbWti3"
   },
   "source": [
    "# Experiment runner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_FxBXOOvtLWC"
   },
   "source": [
    "Create a runner factory. This factory has the ability to create your runners. The factory automatically fills up the environment variables using the `.env` file provided. \n",
    "\n",
    "It fills up the following:\n",
    "- `config_dir`: A path containing all your configuration `yaml` files.\n",
    "- `experiment_dir`: A path containing all your experiments. The result of all the experiments will be stored as directories in this path.\n",
    "- `checkpoint_dir`: A path containing all the model checkpoints which is used for cached run functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "azqIcguUWxka"
   },
   "outputs": [],
   "source": [
    "from mlmnemonist.experiment_factory import ExperimentRunnerFactory\n",
    "from config.config import get_cfg_defaults\n",
    "\n",
    "factory = ExperimentRunnerFactory(config_default_builder=get_cfg_defaults)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "2Eh4tGm5XTOR"
   },
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: './.mnemonic-checkpoints/1-tok-logs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[0;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m      2\u001b[0m token \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1-tok\u001b[39m\u001b[38;5;124m'\u001b[39m \n\u001b[0;32m----> 3\u001b[0m runner \u001b[38;5;241m=\u001b[39m \u001b[43mfactory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconf-test.yaml\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmy_first_experiment\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myprojects/ML-Mnemonist/mlmnemonist/experiment_factory.py:100\u001b[0m, in \u001b[0;36mExperimentRunnerFactory.create\u001b[0;34m(self, experiment_name, verbose, cfg_dir, cache_token)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     98\u001b[0m         cfg_path \u001b[38;5;241m=\u001b[39m cfg_dir\n\u001b[0;32m--> 100\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunner \u001b[38;5;241m=\u001b[39m \u001b[43mExperimentRunner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mcheckpoint_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckpoint_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mcache_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_token\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg_builder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcfg_builder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m                               \u001b[49m\u001b[43msecret_root\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msecret_root\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunner\n",
      "File \u001b[0;32m~/myprojects/ML-Mnemonist/mlmnemonist/experiment_runner.py:54\u001b[0m, in \u001b[0;36mExperimentRunner.__init__\u001b[0;34m(self, experiment_dir, checkpoint_dir, verbose, cache_token, cfg_path, cfg_builder, secret_root)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurring_pipeline \u001b[38;5;241m=\u001b[39m Pipeline()\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocessing_pipeline \u001b[38;5;241m=\u001b[39m Pipeline()\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mCACHE \u001b[38;5;241m=\u001b[39m \u001b[43mRunnerCache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_token\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myprojects/ML-Mnemonist/mlmnemonist/runner_cache.py:39\u001b[0m, in \u001b[0;36mRunnerCache.__init__\u001b[0;34m(self, directory, token)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdirectory \u001b[38;5;241m=\u001b[39m directory\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Create a decoy file\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache_token\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m-logs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: './.mnemonic-checkpoints/1-tok-logs'"
     ]
    }
   ],
   "source": [
    "token = None\n",
    "token = '1-tok' \n",
    "runner = factory.create(cfg_dir='conf-test.yaml', experiment_name='my_first_experiment', \n",
    "                        verbose=1, cache_token=token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hq7nSM-f8ehy",
    "outputId": "01b07a97-a5c5-414c-f84d-9fc60fabd313"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment runner of type: <class 'mlmnemonist.experiment_runner.ExperimentRunner'>\n",
      "\t - cache token: 1-tok\n",
      "\t - configurations at: ./config/conf-test.yaml\n",
      "\t - preprocessings functions []\n",
      "\t - recurring pipeline []\n",
      "\t - Run function not implemented!\n"
     ]
    }
   ],
   "source": [
    "print(runner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U_PEvAX89xMs"
   },
   "source": [
    "# Run a simple linear regression program\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "GFRWSI6F_Af_"
   },
   "outputs": [],
   "source": [
    "from mlmnemonist.experiment_runner import ExperimentRunner\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "fQaHIvGQ_3YG"
   },
   "outputs": [],
   "source": [
    "runner.preprocessing_pipeline.clear_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "PhuvzGFG-86Z"
   },
   "outputs": [],
   "source": [
    "def load_raw_data(runner: ExperimentRunner):\n",
    "  train_name = runner.cfg.DATASET.TRAIN_NAME\n",
    "  test_name = runner.cfg.DATASET.TEST_NAME\n",
    "  runner.train_df = pd.read_csv(runner.reveal_true_path(train_name))\n",
    "  runner.test_df = pd.read_csv(runner.reveal_true_path(test_name))\n",
    "runner.preprocessing_pipeline.update_function(load_raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "3Vo6EsKg_jmk"
   },
   "outputs": [],
   "source": [
    "def process_data(runner: ExperimentRunner):\n",
    "  runner.train_X = runner.train_df.drop(columns='median_house_value').to_numpy()\n",
    "  runner.train_Y = runner.train_df['median_house_value'].to_numpy()\n",
    "  runner.test_X = runner.test_df.drop(columns='median_house_value').to_numpy()\n",
    "  runner.test_Y = runner.test_df['median_house_value'].to_numpy()\n",
    "runner.preprocessing_pipeline.update_function(process_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PuGBf7CgAuwB",
    "outputId": "b74da402-4d9c-4e49-f3d1-6217f65b0230"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment runner of type: <class 'mlmnemonist.experiment_runner.ExperimentRunner'>\n",
      "\t - cache token: 1-tok\n",
      "\t - configurations at: ./config/conf-test.yaml\n",
      "\t - preprocessings functions ['load_raw_data', 'process_data']\n",
      "\t - recurring pipeline []\n",
      "\t - Run function not implemented!\n"
     ]
    }
   ],
   "source": [
    "print(runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o9XySh8pBGwz",
    "outputId": "279a1b1d-764f-4e9b-a8c5-a53d936e709e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/2] Running load_raw_data\n",
      "[2/2] Running process_data\n"
     ]
    }
   ],
   "source": [
    "# Run the functions in line\n",
    "runner.preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dXriKjd6IaYC"
   },
   "source": [
    "## Create a model\n",
    "\n",
    "All models are stored in the `src.modeling` directory. Each modeling file should contain a registry that will give us access to different model types using a configuration. \n",
    "\n",
    "For example, in `conf-test.yaml` we defined an MLP with 3 layers and certain hyper parameters. The following functions are part of preprocessing and setup our model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "4rUEXYL2p-Jx"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MyMLP(nn.Module):\n",
    "    def __init__(self, input_features: int, hidden_layer_1: int, hidden_layer_2: int):\n",
    "        super(MyMLP, self).__init__()\n",
    "        self.l1 = nn.Linear(input_features, hidden_layer_1)\n",
    "        self.l2 = nn.Linear(hidden_layer_1, hidden_layer_2)\n",
    "        self.l3 = nn.Linear(hidden_layer_2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.l2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.l3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "2DdIqwaOSRlR"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "def setup_device(runner: ExperimentRunner):\n",
    "  # extract the device from config\n",
    "  device = runner.cfg.SOLVER.DEVICE\n",
    "  if device == 'cpu':\n",
    "    runner.device = torch.device('cpu')\n",
    "  elif device == 'cuda' and torch.cuda.is_available():\n",
    "    runner.device = torch.device('cuda')\n",
    "  else:\n",
    "    raise NotImplementedError(f\"device {device} is not implemented!\")\n",
    "runner.recurring_pipeline.update_function(setup_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "ort8OLJRIeUQ"
   },
   "outputs": [],
   "source": [
    "\n",
    "def setup_model(runner: ExperimentRunner):\n",
    "  # extract the method from config\n",
    "  method = runner.cfg.SOLVER.METHOD\n",
    "  # construct the model from registry\n",
    "  cfg_h_params = runner.cfg.MODEL.HYPER_PARAMETERS\n",
    "  my_model = MyMLP(input_features=cfg_h_params.IN_FEATURES,\n",
    "                   hidden_layer_1=cfg_h_params.H1,\n",
    "                   hidden_layer_2=cfg_h_params.H2)\n",
    "  # set the function in the cache to save weights\n",
    "  my_model = runner.CACHE.SET_M('mlp-key', my_model)\n",
    "  my_model.to(runner.device)\n",
    "  if runner.verbose > 0:\n",
    "    print(\"Model state dict\")\n",
    "    print(my_model)\n",
    "runner.recurring_pipeline.update_function(setup_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "sGhQ3LKcS-dC"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def setup_training(runner: ExperimentRunner):\n",
    "  my_model = runner.CACHE.GET_M('mlp-key').to(runner.device)\n",
    "  runner.criterion = nn.MSELoss()\n",
    "  if runner.cfg.SOLVER.OPTIMIZER_TYPE == 'adam':\n",
    "    runner.optim = torch.optim.Adam(my_model.parameters(), lr=runner.cfg.SOLVER.LR)\n",
    "  else:\n",
    "    raise NotImplementedError(f\"Optimizer type not implemented\"\n",
    "                              f\"{runner.cfg.SOLVER.OPTIMIZER_TYPE}\")\n",
    "runner.recurring_pipeline.update_function(setup_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m3H9fjChzRRF",
    "outputId": "17f0f93e-66cd-4785-bfa7-99db66b52d8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment runner of type: <class 'mlmnemonist.experiment_runner.ExperimentRunner'>\n",
      "\t - cache token: 1-tok\n",
      "\t - configurations at: ./config/conf-test.yaml\n",
      "\t - preprocessings functions []\n",
      "\t - recurring pipeline ['setup_device', 'setup_model', 'setup_training']\n",
      "\t - Run function not implemented!\n"
     ]
    }
   ],
   "source": [
    "print(runner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57mO42YpH-Ck"
   },
   "source": [
    "# Implement a run function\n",
    "\n",
    "A run function is the core part of an experiment. This function takes in an input of type `ExperimentRunner` type is its first element and a bunch of arbitrary input types for the rest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ajq3MZ0bhlxG",
    "outputId": "05c1c2ab-bf36-49b1-9cda-c9f1ff1f8abc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This will remove all of the variables from your runner's cache ...\n",
      "Are you sure you want to proceed? [y/n] y\n"
     ]
    }
   ],
   "source": [
    "runner.CACHE.RESET()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "0il8pIX8H_uz"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def helper(model, X, y, history, device, loss_fn, optimizer=None):\n",
    "  for st in range(0, X.shape[0], 500):\n",
    "    en = min(st + 500, X.shape[0])\n",
    "    X_ = torch.from_numpy(X[st:en, :]).float().to(device)\n",
    "    pred = model(X_)\n",
    "    y_ = torch.from_numpy(y[st:en]).float().to(device)\n",
    "    loss = loss_fn(pred.squeeze(), y_)\n",
    "    if optimizer is not None:\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "    history.append(loss.detach().cpu().item())\n",
    "    \n",
    "def my_custom_run(runner: ExperimentRunner, show_freq=50):\n",
    "  # print(runner.CACHE._cached_primitives)\n",
    "  # return\n",
    "  # Get model from cache\n",
    "  my_model = runner.CACHE.GET_M('mlp-key')\n",
    "\n",
    "  # Get the epoch number and history from cache\n",
    "  # if it is not cached from before set it to zero\n",
    "  epoch_i = runner.CACHE.SET_IFN('epoch_i', 0)\n",
    "  loss_history = runner.CACHE.SET_IFN('loss-history', [[], []])\n",
    "  for epoch_i in range(epoch_i, 10000):\n",
    "\n",
    "    inds = np.arange(runner.train_X.shape[0])\n",
    "    np.random.shuffle(inds)\n",
    "\n",
    "    loss_train = []\n",
    "    my_model.train()\n",
    "    helper(my_model, runner.train_X[inds],\n",
    "           runner.train_Y[inds], loss_train, runner.device,\n",
    "           runner.criterion, runner.optim)\n",
    "    loss_history[0].append(sum(loss_train) / len(loss_train))\n",
    "\n",
    "    loss_test = []\n",
    "    my_model.eval()\n",
    "    with torch.no_grad():\n",
    "      helper(my_model, runner.test_X,\n",
    "            runner.test_Y, loss_test, runner.device,\n",
    "            runner.criterion)\n",
    "    loss_history[1].append(sum(loss_test) / len(loss_test))\n",
    "    \n",
    "    if (epoch_i + 1) % show_freq == 0:\n",
    "      clear_output()\n",
    "      plt.plot(list(range(len(loss_history[0]))), loss_history[0], label='loss-train')\n",
    "      plt.plot(list(range(len(loss_history[1]))), loss_history[1], label='loss-test')\n",
    "      plt.legend()\n",
    "      plt.show()\n",
    "\n",
    "    # Caching and saving checkpoints\n",
    "    runner.CACHE.SET('epoch_i', epoch_i)\n",
    "    runner.CACHE.SET('loss-history', loss_history)\n",
    "    runner.CACHE.SET_M('mlp-key', my_model)\n",
    "    runner.CACHE.SAVE()\n",
    "\n",
    "runner.implement_run(my_custom_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cc8aGQq_jDAG"
   },
   "source": [
    "Run the following function to see the training and validation loss.\n",
    "Interrupt the process for as many times as you like and re-run it. Since the code supports caching, it will continue right off where it last ended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ixAXNzv72XdZ"
   },
   "outputs": [],
   "source": [
    "del runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "p6IKYVw7dKBo",
    "outputId": "a3436114-2c4a-4dc5-a453-c82cb8b413eb"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshow_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myprojects/ML-Mnemonist/mlmnemonist/experiment_runner.py:127\u001b[0m, in \u001b[0;36mExperimentRunner.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurring_pipeline\u001b[38;5;241m.\u001b[39mrun(keep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose, runner\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mCACHE\u001b[38;5;241m.\u001b[39m_load_cache()\n\u001b[0;32m--> 127\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_implemented_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;66;03m# Save files\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Input \u001b[0;32mIn [32]\u001b[0m, in \u001b[0;36mmy_custom_run\u001b[0;34m(runner, show_freq)\u001b[0m\n\u001b[1;32m     51\u001b[0m   plt\u001b[38;5;241m.\u001b[39mplot(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(loss_history[\u001b[38;5;241m1\u001b[39m]))), loss_history[\u001b[38;5;241m1\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss-test\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     52\u001b[0m   plt\u001b[38;5;241m.\u001b[39mlegend()\n\u001b[0;32m---> 53\u001b[0m   \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Caching and saving checkpoints\u001b[39;00m\n\u001b[1;32m     56\u001b[0m runner\u001b[38;5;241m.\u001b[39mCACHE\u001b[38;5;241m.\u001b[39mSET(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch_i\u001b[39m\u001b[38;5;124m'\u001b[39m, epoch_i)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/pyplot.py:269\u001b[0m, in \u001b[0;36mshow\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;124;03mDisplay a figure.\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;124;03mdescribed above.\u001b[39;00m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m _show\n\u001b[0;32m--> 269\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_show\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib_inline/backend_inline.py:41\u001b[0m, in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m figure_manager \u001b[38;5;129;01min\u001b[39;00m Gcf\u001b[38;5;241m.\u001b[39mget_all_fig_managers():\n\u001b[0;32m---> 41\u001b[0m         \u001b[43mdisplay\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfigure_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fetch_figure_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfigure_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m     show\u001b[38;5;241m.\u001b[39m_to_draw \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/IPython/core/display_functions.py:298\u001b[0m, in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, raw, clear, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    296\u001b[0m     publish_display_data(data\u001b[38;5;241m=\u001b[39mobj, metadata\u001b[38;5;241m=\u001b[39mmetadata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 298\u001b[0m     format_dict, md_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m format_dict:\n\u001b[1;32m    300\u001b[0m         \u001b[38;5;66;03m# nothing to display (e.g. _ipython_display_ took over)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/IPython/core/formatters.py:178\u001b[0m, in \u001b[0;36mDisplayFormatter.format\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    176\u001b[0m md \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;66;03m# FIXME: log the exception\u001b[39;00m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[1;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[0;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcaller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mextras\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/IPython/core/formatters.py:222\u001b[0m, in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;124;03m\"\"\"show traceback on failed format call\"\"\"\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 222\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;66;03m# don't warn on NotImplementedErrors\u001b[39;00m\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_return(\u001b[38;5;28;01mNone\u001b[39;00m, args[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/IPython/core/formatters.py:339\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 339\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprinter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;66;03m# Finally look for special method names\u001b[39;00m\n\u001b[1;32m    341\u001b[0m method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/IPython/core/pylabtools.py:151\u001b[0m, in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_bases\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FigureCanvasBase\n\u001b[1;32m    149\u001b[0m     FigureCanvasBase(fig)\n\u001b[0;32m--> 151\u001b[0m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbytes_io\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m data \u001b[38;5;241m=\u001b[39m bytes_io\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fmt \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvg\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/backend_bases.py:2066\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2064\u001b[0m renderer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39m_cachedRenderer\n\u001b[1;32m   2065\u001b[0m bbox_artists \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbbox_extra_artists\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 2066\u001b[0m bbox_inches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tightbbox\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2067\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbbox_extra_artists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox_artists\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2068\u001b[0m pad \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpad_inches\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   2069\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/figure.py:2376\u001b[0m, in \u001b[0;36mFigure.get_tightbbox\u001b[0;34m(self, renderer, bbox_extra_artists)\u001b[0m\n\u001b[1;32m   2372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ax\u001b[38;5;241m.\u001b[39mget_visible():\n\u001b[1;32m   2373\u001b[0m     \u001b[38;5;66;03m# some axes don't take the bbox_extra_artists kwarg so we\u001b[39;00m\n\u001b[1;32m   2374\u001b[0m     \u001b[38;5;66;03m# need this conditional....\u001b[39;00m\n\u001b[1;32m   2375\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2376\u001b[0m         bbox \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tightbbox\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2377\u001b[0m \u001b[43m                \u001b[49m\u001b[43mbbox_extra_artists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox_extra_artists\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2378\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   2379\u001b[0m         bbox \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39mget_tightbbox(renderer)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/axes/_base.py:4357\u001b[0m, in \u001b[0;36m_AxesBase.get_tightbbox\u001b[0;34m(self, renderer, call_axes_locator, bbox_extra_artists)\u001b[0m\n\u001b[1;32m   4354\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_aspect()\n\u001b[1;32m   4356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxison:\n\u001b[0;32m-> 4357\u001b[0m     bb_xaxis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxaxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tightbbox\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4358\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bb_xaxis:\n\u001b[1;32m   4359\u001b[0m         bb\u001b[38;5;241m.\u001b[39mappend(bb_xaxis)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/axis.py:1162\u001b[0m, in \u001b[0;36mAxis.get_tightbbox\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_visible():\n\u001b[1;32m   1160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m-> 1162\u001b[0m ticks_to_draw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_ticks\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_label_position(renderer)\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;66;03m# go back to just this axis's tick labels\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/axis.py:1080\u001b[0m, in \u001b[0;36mAxis._update_ticks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1075\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;124;03mUpdate ticks (position and labels) using the current data interval of\u001b[39;00m\n\u001b[1;32m   1077\u001b[0m \u001b[38;5;124;03mthe axes.  Return the list of ticks that will be drawn.\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1079\u001b[0m major_locs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_majorticklocs()\n\u001b[0;32m-> 1080\u001b[0m major_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmajor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_ticks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmajor_locs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1081\u001b[0m major_ticks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_major_ticks(\u001b[38;5;28mlen\u001b[39m(major_locs))\n\u001b[1;32m   1082\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmajor\u001b[38;5;241m.\u001b[39mformatter\u001b[38;5;241m.\u001b[39mset_locs(major_locs)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/ticker.py:259\u001b[0m, in \u001b[0;36mFormatter.format_ticks\u001b[0;34m(self, values)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformat_ticks\u001b[39m(\u001b[38;5;28mself\u001b[39m, values):\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;124;03m\"\"\"Return the tick labels for all the ticks at once.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 259\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_locs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m(value, i) \u001b[38;5;28;01mfor\u001b[39;00m i, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(values)]\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/ticker.py:688\u001b[0m, in \u001b[0;36mScalarFormatter.set_locs\u001b[0;34m(self, locs)\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_useOffset:\n\u001b[1;32m    687\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_offset()\n\u001b[0;32m--> 688\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_order_of_magnitude\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_format()\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/ticker.py:752\u001b[0m, in \u001b[0;36mScalarFormatter._set_order_of_magnitude\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    750\u001b[0m     oom \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39mfloor(math\u001b[38;5;241m.\u001b[39mlog10(vmax \u001b[38;5;241m-\u001b[39m vmin))\n\u001b[1;32m    751\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 752\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlocs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlocs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[1;32m    753\u001b[0m         val \u001b[38;5;241m=\u001b[39m locs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    754\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "runner.run(show_freq=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-AqjwHsjpML"
   },
   "source": [
    "# Run even after the session is closed\n",
    "\n",
    "Each runner has a cache token associated with it. You can checkout your runner's token using the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "OSKZn4j_jrmH",
    "outputId": "1dcbf48e-5a07-4b5f-db50-17d2e614723f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tok-227'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runner.CACHE.TOKEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M6sVSjy_j5hh"
   },
   "source": [
    "Now re-run your session and when you are creating a runner use the token in the `cache_token=YOUR_TOKEN` variable. That way, when you call `load_cache()` or whenever you re-run the `run()` function. All the variables that have been cached will be reloaded again."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "ExperimentRunnerTutorial.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
