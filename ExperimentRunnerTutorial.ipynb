{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/HamidrezaKmK/ML-Mnemonist/blob/main/ExperimentRunnerTutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rE6olttuFV0Q"
   },
   "source": [
    "# Setup hosted runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eOfp_NGbT1jZ",
    "outputId": "79649df5-19a7-4f4a-a2a6-f49a6cc498c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing sys_setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile sys_setup.py\n",
    "#!usr/bin/bash python\n",
    "\n",
    "import sys\n",
    "from google.colab import drive\n",
    "import subprocess\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "PROJ_NAME = 'ML-Mnemonist'\n",
    "GIT_DIR = 'HamidrezaKmK'\n",
    "\n",
    "data_dir = None\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  env = os.environ.copy()\n",
    "  if not os.path.exists('/content/drive'):\n",
    "    print(\"Mounting drive...\")\n",
    "    drive.mount('/content/drive')\n",
    "    print(\"Mount complete!\")\n",
    "\n",
    "  while True:\n",
    "    opt = input(\"What are you trying to do? [clone/pull] \")\n",
    "    if opt == 'clone':\n",
    "      addr = f\"https://github.com/{GIT_DIR}/{PROJ_NAME}\"\n",
    "      print(f\"Trying to connect to {addr}\")\n",
    "      token = input(\"Enter token: \")\n",
    "      addr = addr.replace('[TOKEN]', token)\n",
    "      res = subprocess.run(['git', 'clone', addr], env=env, capture_output=True)\n",
    "      print(res.stdout.decode())\n",
    "      print(res.stderr.decode())\n",
    "      break\n",
    "    elif opt == 'pull':\n",
    "      path = os.path.join('/content', PROJ_NAME)\n",
    "      os.chdir(path)\n",
    "      res = subprocess.run(['git', 'pull'], env=env, capture_output=True)\n",
    "      print(res.stdout.decode())\n",
    "      print(res.stderr.decode())\n",
    "      break\n",
    "    elif opt == '':\n",
    "      print(\"Nothing happened!\")\n",
    "      break\n",
    "  \n",
    "  if not os.path.exists(f'/content/{PROJ_NAME}'):\n",
    "    raise RuntimeError(\"No project repository available!\")\n",
    "\n",
    "  if not os.path.exists(f'/content/{PROJ_NAME}/.env'):\n",
    "    print(\"Dotenv non-existant!\")\n",
    "    while True:\n",
    "      resp = input(\"Do you want to enter the file in the prompt or copy it?\\n[copy/write] \")\n",
    "      if resp == 'copy':\n",
    "        dir = input(\"Enter the directory to copy: \")\n",
    "        shutil.copyfile(dir, f'/content/{PROJ_NAME}/.env')\n",
    "      elif resp == 'write':\n",
    "        print(\"Enter the lines in format ENV_VARIABLE_NAME=VALUE\")\n",
    "        print(\"End with: ENDFILE\")\n",
    "        with open(f'/content/{PROJ_NAME}/.env', 'w') as f:\n",
    "          while True:\n",
    "            line = input()\n",
    "            if line == 'ENDFILE':\n",
    "              break\n",
    "            f.write(f'{line}\\n')\n",
    "      else:\n",
    "        continue\n",
    "      break\n",
    "        \n",
    "  os.chdir('/content')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "mzkBQqSLUWC3",
    "outputId": "2d475291-ff6f-430d-da51-06a1eb22bb66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running complete!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PROJ_NAME = 'ML-Mnemonist'\n",
    "\n",
    "from IPython.display import clear_output\n",
    "%run /content/sys_setup.py\n",
    "resp = input(\"Do you want to install packages? [y/n] \")\n",
    "if resp == 'y':\n",
    "  !pip install -r /content/ML-Mnemonist/requirements.txt\n",
    "  input(\"Requrements installed! -- press any key to continue ...\")\n",
    "clear_output()\n",
    "\n",
    "import sys\n",
    "sys.path.append(f'/content/{PROJ_NAME}')\n",
    "os.chdir(f'/content/{PROJ_NAME}')\n",
    "print(\"Running complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iNiIuYQbWti3"
   },
   "source": [
    "# Experiment runner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_FxBXOOvtLWC"
   },
   "source": [
    "Create a runner factory. This factory has the ability to create your runners. The factory automatically fills up the environment variables using the `.env` file provided. \n",
    "\n",
    "It fills up the following:\n",
    "- `config_dir`: A path containing all your configuration `yaml` files.\n",
    "- `experiment_dir`: A path containing all your experiments. The result of all the experiments will be stored as directories in this path.\n",
    "- `checkpoint_dir`: A path containing all the model checkpoints which is used for cached run functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "azqIcguUWxka"
   },
   "outputs": [],
   "source": [
    "from mlmnemonist.experiment_factory import ExperimentRunnerFactory\n",
    "from config.config import get_cfg_defaults\n",
    "\n",
    "factory = ExperimentRunnerFactory(config_default_builder=get_cfg_defaults)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "2Eh4tGm5XTOR"
   },
   "outputs": [],
   "source": [
    "runner = factory.create(cfg_dir='conf-test.yaml', experiment_name='my_first_experiment', \n",
    "                        verbose=1, cache_token='tok-227')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hq7nSM-f8ehy",
    "outputId": "01b07a97-a5c5-414c-f84d-9fc60fabd313"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment runner of type: <class 'mlmnemonist.experiment_runner.ExperimentRunner'>\n",
      "\t - cache token: tok-227\n",
      "\t - configurations at: ./config/conf-test.yaml\n",
      "\t - preprocessings functions []\n",
      "\t - recurring pipeline []\n",
      "\t - Run function not implemented!\n"
     ]
    }
   ],
   "source": [
    "print(runner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U_PEvAX89xMs"
   },
   "source": [
    "# Run a simple linear regression program\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "GFRWSI6F_Af_"
   },
   "outputs": [],
   "source": [
    "from mlmnemonist.experiment_runner import ExperimentRunner\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "fQaHIvGQ_3YG"
   },
   "outputs": [],
   "source": [
    "runner.preprocessing_pipeline.clear_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "PhuvzGFG-86Z"
   },
   "outputs": [],
   "source": [
    "def load_raw_data(runner: ExperimentRunner):\n",
    "  train_name = runner.cfg.DATASET.TRAIN_NAME\n",
    "  test_name = runner.cfg.DATASET.TEST_NAME\n",
    "  runner.train_df = pd.read_csv(runner.reveal_true_path(train_name))\n",
    "  runner.test_df = pd.read_csv(runner.reveal_true_path(test_name))\n",
    "  print(runner.train_df.head())\n",
    "runner.preprocessing_pipeline.update_function(load_raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "3Vo6EsKg_jmk"
   },
   "outputs": [],
   "source": [
    "def process_data(runner: ExperimentRunner):\n",
    "  runner.train_X = runner.train_df.drop(columns='median_house_value').to_numpy()\n",
    "  runner.train_Y = runner.train_df['median_house_value'].to_numpy()\n",
    "  runner.test_X = runner.test_df.drop(columns='median_house_value').to_numpy()\n",
    "  runner.test_Y = runner.test_df['median_house_value'].to_numpy()\n",
    "runner.preprocessing_pipeline.update_function(process_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PuGBf7CgAuwB",
    "outputId": "b74da402-4d9c-4e49-f3d1-6217f65b0230"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment runner of type: <class 'mlmnemonist.experiment_runner.ExperimentRunner'>\n",
      "\t - cache token: tok-227\n",
      "\t - configurations at: ./config/conf-test.yaml\n",
      "\t - preprocessings functions ['load_raw_data', 'process_data']\n",
      "\t - recurring pipeline []\n",
      "\t - Run function not implemented!\n"
     ]
    }
   ],
   "source": [
    "print(runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o9XySh8pBGwz",
    "outputId": "279a1b1d-764f-4e9b-a8c5-a53d936e709e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/2] Running load_raw_data\n",
      "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
      "0    -114.31     34.19                15.0       5612.0          1283.0   \n",
      "1    -114.47     34.40                19.0       7650.0          1901.0   \n",
      "2    -114.56     33.69                17.0        720.0           174.0   \n",
      "3    -114.57     33.64                14.0       1501.0           337.0   \n",
      "4    -114.57     33.57                20.0       1454.0           326.0   \n",
      "\n",
      "   population  households  median_income  median_house_value  \n",
      "0      1015.0       472.0         1.4936             66900.0  \n",
      "1      1129.0       463.0         1.8200             80100.0  \n",
      "2       333.0       117.0         1.6509             85700.0  \n",
      "3       515.0       226.0         3.1917             73400.0  \n",
      "4       624.0       262.0         1.9250             65500.0  \n",
      "[2/2] Running process_data\n"
     ]
    }
   ],
   "source": [
    "# Run the functions in line\n",
    "runner.preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dXriKjd6IaYC"
   },
   "source": [
    "## Create a model\n",
    "\n",
    "All models are stored in the `src.modeling` directory. Each modeling file should contain a registry that will give us access to different model types using a configuration. \n",
    "\n",
    "For example, in `conf-test.yaml` we defined an MLP with 3 layers and certain hyper parameters. The following functions are part of preprocessing and setup our model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "4rUEXYL2p-Jx"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MyMLP(nn.Module):\n",
    "    def __init__(self, input_features: int, hidden_layer_1: int, hidden_layer_2: int):\n",
    "        super(MyMLP, self).__init__()\n",
    "        self.l1 = nn.Linear(input_features, hidden_layer_1)\n",
    "        self.l2 = nn.Linear(hidden_layer_1, hidden_layer_2)\n",
    "        self.l3 = nn.Linear(hidden_layer_2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.l2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.l3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ort8OLJRIeUQ"
   },
   "outputs": [],
   "source": [
    "\n",
    "def setup_model(runner: ExperimentRunner):\n",
    "  # extract the method from config\n",
    "  method = runner.cfg.SOLVER.METHOD\n",
    "  # construct the model from registry\n",
    "  cfg_h_params = runner.cfg.MODEL.HYPER_PARAMETERS\n",
    "  my_model = MyMLP(input_features=cfg_h_params.IN_FEATURES,\n",
    "                   hidden_layer_1=cfg_h_params.H1,\n",
    "                   hidden_layer_2=cfg_h_params.H2)\n",
    "  # set the function in the cache to save weights\n",
    "  runner.CACHE.SET_IFN_M('mlp-key', my_model)\n",
    "runner.preprocessing_pipeline.update_function(setup_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "2DdIqwaOSRlR"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "def setup_device(runner: ExperimentRunner):\n",
    "  # extract the device from config\n",
    "  device = runner.cfg.SOLVER.DEVICE\n",
    "  if device == 'cpu':\n",
    "    runner.device = torch.device('cpu')\n",
    "  elif device == 'cuda' and torch.cuda.is_available():\n",
    "    runner.device = torch.device('cuda')\n",
    "  else:\n",
    "    raise NotImplementedError(f\"device {device} is not implemented!\")\n",
    "  my_model = runner.CACHE.GET_M('mlp-key').to(runner.device)\n",
    "  if runner.verbose > 0:\n",
    "    print(\"Printing the model state_dict\")\n",
    "    print(my_model)\n",
    "runner.preprocessing_pipeline.update_function(setup_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "sGhQ3LKcS-dC"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def setup_training(runner: ExperimentRunner):\n",
    "  my_model = runner.CACHE.GET_M('mlp-key').to(runner.device)\n",
    "  runner.criterion = nn.MSELoss()\n",
    "  if runner.cfg.SOLVER.OPTIMIZER_TYPE == 'adam':\n",
    "    runner.optim = torch.optim.Adam(my_model.parameters(), lr=runner.cfg.SOLVER.LR)\n",
    "  else:\n",
    "    raise NotImplementedError(f\"Optimizer type not implemented\"\n",
    "                              f\"{runner.cfg.SOLVER.OPTIMIZER_TYPE}\")\n",
    "runner.preprocessing_pipeline.update_function(setup_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m3H9fjChzRRF",
    "outputId": "17f0f93e-66cd-4785-bfa7-99db66b52d8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment runner of type: <class 'mlmnemonist.experiment_runner.ExperimentRunner'>\n",
      "\t - cache token: tok-227\n",
      "\t - configurations at: ./config/conf-test.yaml\n",
      "\t - preprocessings functions ['setup_model', 'setup_device', 'setup_training']\n",
      "\t - recurring pipeline []\n",
      "\t - Run function not implemented!\n"
     ]
    }
   ],
   "source": [
    "print(runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3QsSTXLDzTPz",
    "outputId": "b551a9f5-57e2-4a1a-df6b-2242d4f54a4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/3] Running setup_model\n",
      "[2/3] Running setup_device\n",
      "Printing the model state_dict\n",
      "MyMLP(\n",
      "  (l1): Linear(in_features=8, out_features=100, bias=True)\n",
      "  (l2): Linear(in_features=100, out_features=10, bias=True)\n",
      "  (l3): Linear(in_features=10, out_features=1, bias=True)\n",
      ")\n",
      "[3/3] Running setup_training\n"
     ]
    }
   ],
   "source": [
    "runner.preprocess(keep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57mO42YpH-Ck"
   },
   "source": [
    "# Implement a run function\n",
    "\n",
    "A run function is the core part of an experiment. This function takes in an input of type `ExperimentRunner` type is its first element and a bunch of arbitrary input types for the rest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ajq3MZ0bhlxG",
    "outputId": "05c1c2ab-bf36-49b1-9cda-c9f1ff1f8abc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This will remove all of the variables from your runner's cache ...\n",
      "Are you sure you want to proceed? [y/n] n\n"
     ]
    }
   ],
   "source": [
    "runner.CACHE.RESET()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "0il8pIX8H_uz"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def helper(model, X, y, history, device, loss_fn, optimizer=None):\n",
    "  for st in range(0, X.shape[0], 500):\n",
    "    en = min(st + 500, X.shape[0])\n",
    "    X_ = torch.from_numpy(X[st:en, :]).float().to(device)\n",
    "    pred = model(X_)\n",
    "    y_ = torch.from_numpy(y[st:en]).float().to(device)\n",
    "    loss = loss_fn(pred.squeeze(), y_)\n",
    "    if optimizer is not None:\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "    history.append(loss.detach().cpu().item())\n",
    "    \n",
    "def my_custom_run(runner: ExperimentRunner, show_freq=50):\n",
    "  # print(runner.CACHE._cached_primitives)\n",
    "  # return\n",
    "  # Get model from cache\n",
    "  my_model = runner.CACHE.GET_M('mlp-key')\n",
    "\n",
    "  # Get the epoch number and history from cache\n",
    "  # if it is not cached from before set it to zero\n",
    "  epoch_i = runner.CACHE.SET_IFN('epoch_i', 0)\n",
    "  loss_history = runner.CACHE.SET_IFN('loss-history', [[], []])\n",
    "  for epoch_i in range(epoch_i, 10000):\n",
    "\n",
    "    inds = np.arange(runner.train_X.shape[0])\n",
    "    np.random.shuffle(inds)\n",
    "\n",
    "    loss_train = []\n",
    "    my_model.train()\n",
    "    helper(my_model, runner.train_X[inds],\n",
    "           runner.train_Y[inds], loss_train, runner.device,\n",
    "           runner.criterion, runner.optim)\n",
    "    loss_history[0].append(sum(loss_train) / len(loss_train))\n",
    "\n",
    "    loss_test = []\n",
    "    my_model.eval()\n",
    "    with torch.no_grad():\n",
    "      helper(my_model, runner.test_X,\n",
    "            runner.test_Y, loss_test, runner.device,\n",
    "            runner.criterion)\n",
    "    loss_history[1].append(sum(loss_test) / len(loss_test))\n",
    "    \n",
    "    if (epoch_i + 1) % show_freq == 0:\n",
    "      clear_output()\n",
    "      plt.plot(list(range(len(loss_history[0]))), loss_history[0], label='loss-train')\n",
    "      plt.plot(list(range(len(loss_history[1]))), loss_history[1], label='loss-test')\n",
    "      plt.legend()\n",
    "      plt.show()\n",
    "\n",
    "    # Caching and saving checkpoints\n",
    "    runner.CACHE.SET('epoch_i', epoch_i)\n",
    "    runner.CACHE.SET('loss-history', loss_history)\n",
    "    runner.CACHE.SET_M('mlp-key', my_model)\n",
    "    runner.CACHE.SAVE()\n",
    "\n",
    "runner.implement_run(my_custom_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cc8aGQq_jDAG"
   },
   "source": [
    "Run the following function to see the training and validation loss.\n",
    "Interrupt the process for as many times as you like and re-run it. Since the code supports caching, it will continue right off where it last ended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ixAXNzv72XdZ"
   },
   "outputs": [],
   "source": [
    "del runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "p6IKYVw7dKBo",
    "outputId": "a3436114-2c4a-4dc5-a453-c82cb8b413eb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEDCAYAAAAlRP8qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3dd1yV5fvA8c/N3iCIgAxxb0VFnJnmHqllpZWp6TezvpWNr5Xt+rWn2bBsaqZZjjI1NXOXpuDeuMEFgiAiKOP+/fEcERSRAwcOHK7363VenHM/41wPRy/ucz/3UFprhBBCVH521g5ACCGEZUhCF0IIGyEJXQghbIQkdCGEsBGS0IUQwkZIQhdCCBth1YSulPpWKZWglNpZjH27KKU2K6WylVJ3XLVtpFIq1vQYWXYRCyFExWXtGvr3QJ9i7nsMGAXMzF+olPIFXgbaAVHAy0qpapYLUQghKgerJnSt9RogOX+ZUqquUmqJUipGKbVWKdXItO8RrfV2IPeq0/QG/tRaJ2utzwJ/Uvw/EkIIYTMcrB1AIaYC47TWsUqpdsDnwC1F7B8MxOV7HW8qE0KIKqVCJXSllAfQEfhFKXW52PlGhxVSJvMZCCGqnAqV0DGagFK01hFmHBMPdM33OgRYZcGYhBCiUrD2TdECtNbngMNKqTsBlKHlDQ5bCvRSSlUz3QztZSoTQogqxdrdFmcB64GGSql4pdQY4F5gjFJqG7ALGGTat61SKh64E/hSKbULQGudDPwfsMn0eM1UJoQQVYqS6XOFEMI2VKgmFyGEECVntZui1atX1+Hh4dZ6eyGEqJRiYmLOaK39C9tmtYQeHh5OdHS0td5eCCEqJaXU0ettkyYXIYSwEZLQhRDCRkhCF0IIG1HRRooKIWxAVlYW8fHxZGZmWjuUSsvFxYWQkBAcHR2LfYwkdCGExcXHx+Pp6Ul4eDj55mUSxaS1Jikpifj4eGrXrl3s46TJRQhhcZmZmfj5+UkyLyGlFH5+fmZ/w5GELoQoE5LMS6ckv79K1+RyICGNBdtOEuzjQk0fV4K8Xanp44KbU6W7FCGEsKhKlwX3nkrjkxWxXD0FjZeLAzV9XAn2cSW4mithvm7U8nMn3M+NMD83nB3srROwEMIqPDw8OH/+vMXPm5KSwsyZM3n44YfNPrZfv37MnDkTHx8fi8cFlTChD2hRk95NAzmVmsmJlAxOpGZwKvUip1IzOJ6SyfGUDDYeSSYtMzvvGHs7RS0/N+r5e9AoyIsmQV40relFSDVX+VoohDBLSkoKn3/+eaEJPScnB3v761ceFy9eXJahVb6EDuBob0eorxuhvm7X3SflwiUOn0nnSFI6BxPSOZBwntiENJbvOU2uqXbv5+5ERKgPrcJ8aFfHjxYh3lKTF8LGaK15+umn+eOPP1BK8cILLzB06FBOnjzJ0KFDOXfuHNnZ2UyZMoWOHTsyZswYoqOjUUoxevRonnjiiQLne/bZZzl48CARERH07NmT/v378+qrrxIUFMTWrVvZvXs3gwcPJi4ujszMTMaPH8/YsWOBK1OenD9/nr59+9K5c2f++ecfgoOD+e2333B1dS3VtVbKhF4cPm5OtApzolVYtQLlGZdy2Hc6jZ3HU9kWl8KWuBT+2psAgIujHW3Dfbm5gT/dGtWgTnV3qcELUUqv/r6L3SfOWfScTWp68fKtTYu177x589i6dSvbtm3jzJkztG3bli5dujBz5kx69+7N888/T05ODhcuXGDr1q0cP36cnTt3AkZt/Gpvv/02O3fuZOvWrQCsWrWKjRs3snPnzrwuht9++y2+vr5kZGTQtm1bhgwZgp+fX4HzxMbGMmvWLL766ivuuusu5s6dy/Dhw0vza7HdhH49rk72RIT6EBHqw/D2tQA4m36JjUeSWX8wib8PnOH1RXt4fdEe6lR3p1/zIPo1D6JxkKckdyEqoXXr1nH33Xdjb29PQEAAN998M5s2baJt27aMHj2arKwsBg8eTEREBHXq1OHQoUM8+uij9O/fn169ehXrPaKiogr0F588eTLz588HIC4ujtjY2GsSeu3atYmIMFbbbNOmDUeOHCn1tVa5hF6Yau5O9G4aSO+mgQDEJV9g1b4Elu46zeerDvDpygM0DPBkaNtQbm8djI+bk5UjFqLyKG5NuqxcbxGfLl26sGbNGhYtWsR9993HhAkTGDFiBNu2bWPp0qV89tln/Pzzz7z66qvceuutAIwbN44+ffpccy53d/e856tWrWL58uWsX78eNzc3unbtWmh/cmdn57zn9vb2ZGRklPZSi5fQlVJHgDQgB8jWWkdetb0r8Btw2FQ0T2v9Wqmjs5JQXzfu6xDOfR3COXP+Ikt2nuKX6DheW7ibt5fs5baIYB7oUod6NTysHaoQ4ga6dOnCl19+yciRI0lOTmbNmjW89957HD16lODgYB544AHS09PZvHkz/fr1w8nJiSFDhlC3bl1GjRpFaGhoXvMKQFJSEmlpadd9v9TUVKpVq4abmxt79+5lw4YN5XGZgHk19G5a6zNFbF+rtR5Q2oBu6MwB2LMAvILBO9j46VUTHJxvfGwJVPdwZnj7WgxvX4vdJ87x479HmRMTz88xcfRoHMD47vVpFuxdJu8thCi92267jfXr19OyZUuUUrz77rsEBgYybdo03nvvPRwdHfHw8GD69OkcP36c+++/n9zcXADeeuuta87n5+dHp06daNasGX379qV///4Ftvfp04cvvviCFi1a0LBhQ9q3b18u1wnFXFPUVEOPvF5CN9XQ/2dOQo+MjNQlWuBixxyYO+bacnd/8A6BauGmR22oXh/86hnbLNj+nXT+ItPWH2XaP0dIzciif/MgnujZQGrsQpjs2bOHxo0bWzuMSq+w36NSKubqVpK8bcVM6IeBs4AGvtRaT71qe1dgLhAPnMBI7rsKOc9YYCxAWFhYm6NHr7vwRtEupcO5E5AaD+eOX3mecgxSjkJKHORmXdnftRrUaAI1GkNgC6gZAf6NwaF0beHnMrP4es0hvll3mMzsXO5rX4snejTA2634s6MJYYskoVtGWSX0mlrrE0qpGsCfwKNa6zX5tnsBuVrr80qpfsDHWuv6RZ2zxDX04sjNgdQ4SDoAZ2IhcS8k7IHTu+GSqe3L3hlqtoLQKAjrAOGdwKVkTSdJ5y8yaXksP/57FG9XRyb0bsSwtqHY2UmvGFE1SUK3jDJJ6Fed7BXgvNb6/SL2OUIRTTRQxgn9enJz4exhOLkVjm+GuI3G85xLoOwguA3UvQUa9oWgCLObaXafOMcrv+9i4+FkosJ9eXtIc+r4SzOMqHokoVuGuQn9hjdFlVLugJ3WOs30vBfw2lX7BAKntdZaKRWFMYtjUgmvoezY2YFfXePRbIhRlpUJx6Ph0Co4uBLWvAer3wHPmtD4VmgxFIJbFyu5N6npxeyx7fklJp7XF+6mz8dreapnAx64qY7U1oUQZa44vVwCgPmmQTUOwEyt9RKl1DgArfUXwB3AQ0qpbCADGKbNrfpbi6MLhHc2Hre8AOlnYP9S2LcYYr6HjV8aN1ZbDYdWI8Ddr8jTKaW4KzKUrg38efG3nbz1x15W70/ko6ERBHi5lM81CSGqJLObXCzFKk0u5spIMbpIbvsJjv5ttLs3vwM6PAIBTW54uNaan6PjeGXBblwc7Xj/zpZ0bxxQDoELYV3S5GIZ5ja5yAIXRXH1gdYj4P7F8PAGo5a+61eY0gF+uhdObC3ycKUUQ9uGsfCxztT0cWXMtGgmLd9Pbm7l+PIiRGXm4VE2968uz7ZYUpMmTeLChQsWjOgKSejFVaMxDPgQntgJNz8Dh9fC1Jvh5xGQdLDIQ+v6ezD3oY7c3jqYSctjGftDDGmZWUUeI4SomCSh2xI3X+j2HDyxA25+FmKXw2dRsHgCZJy97mEujvZ8cGdLXrm1CSv3JXDHlPWcSCn93A1CiKJprZkwYQLNmjWjefPmzJ49G4CTJ0/SpUsXIiIiaNasGWvXriUnJ4dRo0bl7fvRRx9dc7780+dOmDABgPfee4+2bdvSokULXn75ZQDS09Pp378/LVu2pFmzZsyePZvJkydz4sQJunXrRrdu3Sx+rTI5V0m5eEO3iRB5P6x6GzZ9DTvnQa/XoeWwQnvFKKUY1ak29Wp48tCMGAZ/9jffjmorUwcI2/bHs3Bqh2XPGdgc+r5drF3LevrcZcuWERsby8aNG9FaM3DgQNasWUNiYiI1a9Zk0aJFgDHHi7e3Nx9++CErV66kevXqFvplXCE19NLyDIRbJ8HY1eBbG34dB98PgORD1z2kc/3q/PJQBxzsFEO/XM+62KKmyBFClEZR0+d+9913vPLKK+zYsQNPT88C0+cuWbIELy+vG55/2bJlLFu2jFatWtG6dWv27t1LbGwszZs3Z/ny5TzzzDOsXbsWb++yr7hJDd1SglrA6GWwZTosexGmdIZer0HkmEJr640CvZj/306M/HYjo7/fxGf3tqZnE+kBI2xQMWvSZaWsp8/VWjNx4kQefPDBa94jJiaGxYsXM3HiRHr16sVLL71k+Qu8OhhrPNq0aaNtVkqc1tMGaf2yl9bTB2udlnDdXc+mX9QDP1mr60xcpH/berwcgxSi7OzevdvaIWh3d3ettdZz587VvXr10tnZ2TohIUGHhYXpkydP6iNHjuisrCyttdYfffSRHj9+vE5MTNSpqalaa623bNmiW7Zsec15z5w5o8PCwvJeL126VEdFRem0tDSttdbx8fH69OnT+vjx4zojI0NrrfX8+fP1oEGDtNZaN2vWTB86dKhY11DY7xGI1tfJq1JDLwveIXDffKNdfenz8EVnuOMbY/DSVXzcnJjxn3aMmRbN+J+2oLVmUESwFYIWwjaV9fS57733Hnv27KFDhw6A0V1yxowZHDhwgAkTJmBnZ4ejoyNTpkwBYOzYsfTt25egoCBWrlxp0WuVgUVl7dQO+GWU0aZ+y4vQ+YlCm2AyLuUw6ruNRB89y5R7W9PLtHqSEJWRDCyyDBlYVNEENoexq6DJYPjrVZj3AGRd213R1cmeb0a1pXmwN4/M3MLa2MRyD1UIUblJQi8Pzp5wx7dGDX3HL/BdPzh38prdPJwdmHZ/FHVrePDA9Gi2HLt+v3YhhLiaJPTyohR0+R8MmwmJ++CbXsZc7VfxdnNk+ugoani6MGZaNIfPpFshWCFKz1rNubaiJL8/SejlrVF/uH8RZF0wknp8zDW7+Hs6M210FACjvtvImfMXyztKIUrFxcWFpKQkSeolpLUmKSkJFxfzZmiVm6LWknQQfrgN0hPh7llQp+s1u2w5dpa7v9pAwwBPZj/YARdH+3IPU4iSyMrKIj4+nszMTGuHUmm5uLgQEhKCo2PBJS0tumKRpVT5hA6Qdhp+GGz0gLl7lrFa0lWW7TrFgzNiGNCiJpOHRaAsuNi1EKLykV4uFZVnAIz83VhAY+YwOLD8ml16NQ3kf70a8vu2E3y+quhZHYUQVZskdGtzrw4jFoB/A5h1j7EU3lUe7lqXQRE1eW/pPpbuOlX+MQohKgVJ6BWBu5+R1P3qGgtnHC94o1QpxTtDWtAyxJunft7GocTzVgpUCFGRSUKvKNx8Yfg8cPODGXcYXRvzcXG05/PhbXC0Vzz842YyLuVYKVAhREUlCb0i8QqCEb+CvSNMHwypxwtsDvZx5eNhrdh3Oo3nf90hXcKEEAVIQq9ofOsYNfWLaTBrqPEzny4N/BnfvT7zNh/np01xVgpSCFERSUKviAKbwV3fw+ndMGc05GQX2PzYLfW5qX51Xlmwi32n0go/hxCiyilWQldKHVFK7VBKbVVKXdN5XBkmK6UOKKW2K6VaWz7UKqZeD+j/PsQugyXPFthkZ6f48K4IPF0ceHSWtKcLIQzm1NC7aa0jrtOhvS9Q3/QYC0yxRHBVXuRo6PAIbPoKYqYV2OTv6cyHd0Ww//R5/m/RbisFKISoSCzV5DIImG5aUGMD4KOUCrLQuau2nq8ZI0gX/w/iNhbY1KWBPw92qcPMf4+xZOe1szcKIaqW4iZ0DSxTSsUopcYWsj0YyH+HLt5UVoBSaqxSKlopFZ2YKPN9F4udPQz5Brxqwuz7rpl296leDWke7M3EeTtISJN5M4Soyoqb0DtprVtjNK38VynV5arthU0wck2fOq31VK11pNY60t/f38xQqzA3X2Pa3Ytp8MtIyMnK2+TkYMdHQ1ty4VIOE+dKV0YhqrJiJXSt9QnTzwRgPhB11S7xQGi+1yHACUsEKEwCmsKgTyDuX/jrtQKb6tXw5Jk+jfhrbwKzpSujEFXWDRO6UspdKeV5+TnQC9h51W4LgBGm3i7tgVSttTTqWlqzIRA5Bv6ZDPuWFNg0qmM4Hev68drC3RxLumClAIUQ1lScGnoAsE4ptQ3YCCzSWi9RSo1TSo0z7bMYOAQcAL4CHi6TaAX0fhMCW8D8ByHlSm3czk7x3p0tsVeKZ+ZuJzdXml6EqGpkPvTKKOkgTO0KNRrDqMVg75C3adbGY0yct4PXBzdjePta1otRCFEmZD50W+NXF/p/aLSnr/2gwKZhbUPpXK86by3eQ/xZaXoRoiqRhF5ZtbgTWgyF1e8U6J+ulOKt25ujgYnzpNeLEFWJJPTKrN/74B0Cc/8DmefyikN93ZjYtxFrY88wb/PxIk4ghLAlktArMxcvGPI1pMZfM9/Lve1q0TrMh9cX7SY5/ZKVAhRClCdJ6JVdaBR0fgK2/gj7/sgrtrNTvHV7C9Iys3lz8R4rBiiEKC+S0G3Bzc9AQDNY8BhcSM4rbhjoydgudZgTE8/6g0lWDFAIUR4kodsCBye47QvIOAuLniqw6dFb6hPm68bz83dwMVum2RXClklCtxWBzaHrs7BrHuz6Na/Y1cme1wY15dCZdL5ee9iKAQohypokdFvS6XEIagmLJxRoeunasAa9mgTw6YoDHE/JsGKAQoiyJAndltg7wMBP4UISLHuxwKYXBzQhV2vekMUwhLBZktBtTVAL6DQets6AgyvyikN93fhvt3os3nGKdbFnrBigEKKsSEK3RTc/A3714PfxcCk9r3hslzrU8nPj5QU7ycrJtWKAQoiyIAndFjm6wMBPIOUYrH43r9jF0Z7n+zXmYGI6M/89ZsUAhRBlQRK6rarVESKGw/pPIeHKwKKeTQLoWNePj5bvJ/VCVhEnEEJUNpLQbVnP18DZ0+ibbpqkSynFC/2bkJqRxeQVsVYOUAhhSZLQbZm7H/R4FY7+Ddtm5RU3qenF0MhQpq8/wuEz6dc/XghRqUhCt3Wt7oOQKFj2gjGS1OTJXg1wsreTeV6EsCGS0G2dnR30/8BI5qveySuu4enCQ13r8ufu02w8nFzECYQQlYUk9KogqAW0Hgkbp0LC3rziMZ3rEOjlwhuL98hCGELYAEnoVcUtL4KzhzFvuil5uzrZ82SvBmyLS2Hh9pNWDlAIUVqS0KsKdz/o9jwcWgn7FucVD2kdQqNAT95duldmYxSikpOEXpVEjgH/xrD0Oci+CIC9neK5fo2JS87gh/VHrRygEKI0ip3QlVL2SqktSqmFhWzrqpRKVUptNT1esmyYwiLsHaD3G3D2CGz8Kq+4SwN/bqpfnU9XHuBcpgw2EqKyMqeGPh4oqo/bWq11hOnxWinjEmWlXneo1wPWvFtgit1n+jQi5UIWU1cfsmJwQojSKFZCV0qFAP2Br8s2HFEuer0OF9Ng9ZVujM2CvRnQIohv1h0m4VymFYMTQpRUcWvok4CngaKm6OuglNqmlPpDKdW0sB2UUmOVUtFKqejExERzYxWWUqOx0Y1x09dw5kBe8f96NSQrJ1emBBCikrphQldKDQAStNYxRey2GailtW4JfAL8WthOWuupWutIrXWkv79/iQIWFtLtOXBwgeUv5xWFV3dnWFQoP22M44hMCSBEpVOcGnonYKBS6gjwE3CLUmpG/h201ue01udNzxcDjkqp6pYOVliQRw1jybq9C+HYhrzix7rXx9Hejo+W77dicEKIkrhhQtdaT9Rah2itw4FhwAqt9fD8+yilApVSyvQ8ynTepDKIV1hSh4fBIxD+fDlvsFENTxdGdQpnwbYT7D11zsoBCiHMUeJ+6EqpcUqpcaaXdwA7lVLbgMnAMC1jySs+J3fo+izEbSgw2OjBLnXwcHLgg2VSSxeiMlHWyruRkZE6OjraKu8t8snJhikdjOcPrTf6qgOf/BXLB3/uZ/7DHWkVVs2KAQoh8lNKxWitIwvbJiNFqzp7B+j+MpzZbywsbXJ/59r4uTvx/rJ9VgxOCGEOSegCGvU35kxf9Q5kZQDg4ezAQ13r8veBJP45cMbKAQohikMSugCloMfLkHaiwJQAw9vXItDLhQ/+3C/T6wpRCUhCF4bwzsaUAOs+hMxUAFwc7XnklnrEHD3Lqv0yEEyIik4Surii+0vGykb/fJpXdFdkKKG+rnywbJ/U0oWo4CShiyuCWkLT22D9Z3A+AQAnBzvGd2/AzuPnWLrrtJUDFEIURRK6KKjbC5CdCWs/zCsaHFGTOv7ufPTnfnJzpZYuREUlCV0UVL0eRNwN0d9AajwADvZ2PN6jAftOp7FohyxVJ0RFJQldXOvmZ4ypANa8l1fUv3kQDQI8mLR8PzlSSxeiQpKELq7lEwaR98OWGZBsLHhhb6d4vEcDDiams3D7CSsHKIQojCR0UbibngI7R2OwkUmfpoE0CvTk4+WxZOcUNTW+EMIaJKGLwnkGQtQDsH02JOwFwM5USz90Jp3ftkotXYiKRhK6uL5OjxszMq5+O6+od9MAmgR5MXmF1NKFqGgkoYvrc/eDduNg13w4vQsApRSP96jP0aQLzN9y3MoBCiHyk4Quitbhv+DsBaveyivq2SSAZsFefLLiAFlSSxeiwpCELorm5gvtH4Y9v8PJbYCplt69AceSpZYuREUiCV3cWPuHwMUbVl6ppXdvXIPmwd58siJWaulCVBCS0MWNufpAh0dh/x9wfDNwpS09LjmD+Zulli5ERSAJXRRPuwfBtRqsutLj5ZZGNWgR4s1kqaULUSFIQhfF4+IFHR6B2KVwPAYwaunju9cn/qzU0oWoCCShi+KLGltoLb15sDefrJRauhDWJgldFJ+LF3R8FGKXQfyVWnpeW7r0eBHCqiShC/NEjQVX3wL90i/X0j+VfulCWFWxE7pSyl4ptUUptbCQbUopNVkpdUAptV0p1dqyYYoKw9nTqKUf+LNALX189/rSL10IKzOnhj4e2HOdbX2B+qbHWGBKKeMSFVnUA0Zber45Xro3rkGzYC+ppQthRcVK6EqpEKA/8PV1dhkETNeGDYCPUirIQjGKiuZyLT12WYEeLzJ6VAjrKm4NfRLwNHC9qlcwEJfvdbyprACl1FilVLRSKjoxMdGsQEUFk9fj5cp86ZdHj0otXQjruGFCV0oNABK01jFF7VZI2TXrlGmtp2qtI7XWkf7+/maEKSocZ898/dILjh6VWroQ1lGcGnonYKBS6gjwE3CLUmrGVfvEA6H5XocAsgKCrYsaCy4+sPpKLV16vAhhPTdM6FrriVrrEK11ODAMWKG1Hn7VbguAEabeLu2BVK21LA9v6y6PHt2/BE5sBa6qpcvoUSHKVYn7oSulximlxpleLgYOAQeAr4CHLRCbqAzajTVmYlz9bl7R5TleZPSoEOXLrISutV6ltR5gev6F1voL03Ottf6v1rqu1rq51jq6LIIVFZCLtzFf+r5FcHI7IDMxCmEtMlJUlF67ceDsDWuu1NK7NZRauhDlTRK6KD1XH2g/zljV6NROQGrpQliDJHRhGe0fAidPqaULYUWS0IVluFYzFsHYvQASjBki8tfS58bEWzlAIWyfJHRhOR3+C07usOa9vKJuDWvQMtSHT1Yc4FK21NKFKEuS0IXluPkaE3ftnAeJ+wGjlv5Ej/ocT8lgjtTShShTktCFZXV4FBzdCtTSb27gT6swHz5dEcvF7BwrBieEbZOELizL3Q/ajoGdc+DMAcCopT/ZswEnUjP5OVpq6UKUFUnowvI6Pgb2zrD2/byizvWqE1mrGp+tOEBmltTShSgLktCF5Xn4G7X07T9D0kHgSi391LlMZm08ZuUAhbBNktBF2ej4GNg7wtoPrhTVq077Or58vuogGZekli6EpUlCF2XDMwAiR8O2nyD5UF7xkz0bkph2kRkbjloxOCFskyR0UXY6jQc7B1j7YV5RVG1fbqpfnSmrD5J+MduKwQlheyShi7LjGQhtRsG2WXD2SF7xEz0bkJx+ie//OXK9I4UQJeBg7QCEjev8OMR8b9TSB04GoHVYNbo19GfqmkPc16EWXi6O1o1RFMu5zCxW7Utk+e7T7D11jvOZ2Zy/mE01dydahfrQulY1ejUJJNDbxdqhVllK62uW/iwXkZGROjpapk2vEhZPgOhv4dHNUK0WADviU7n103U81r0+T/ZsYOUARVGS0y/xwbJ9/BwdR1aOxs/diTa1quHp4oiHsz2nzmWy+VgKiWkXcbK34662ITzUtR7BPq7WDt0mKaVitNaRhW2TGrooe52fMNXSP8irpTcP8aZP00C+XXeYUR3D8XV3sm6M4ho5uZof1h/hwz/3k34ph7ujQhkcEUyrsGrY2xVcF15rzZGkC3y19hCzN8Uxe1McD3etx6O31MPBXlp2y4v8pkXZ86oJrUfC1h8h5Uof9Cd7NSD9UjZfrj5oxeBEYRLOZXLv1xt45ffdtAjxYcn4m3h9cHMiw32vSeZgjDOoXd2dN29rzuoJ3ejfPIiP/4pl6NQNxCVfsMIVVE2S0EX56PwEKLsC/dIbBHgyOCKYaeuPkHAu03qxiQL+PnCGfpPXsTUuhffuaMEPY6KoH+BZ7ONr+rgyaVgrPh4Wwf5TafT7eC3rDyaVYcTiMknoonx4Bxu19C0zCtTSH+9Rn6wczWcrD1gxOHHZnJh47vvmX6q5ObLgkc7cGRmKUtfWyItjUEQwi8ffRIC3C6O/38S/hySplzVJ6KL8XK6lr7kyx0stP3fuigxl5sZjHEuSr+bWNHvTMSbM2UbHutX57ZFONDCjVn49ob5uzHygHTV9XLj/+01sOpJsgUjF9UhCF5EpTd8AAB+jSURBVOXHO9jol771xwL90sd3r4+dUny0fL/VQqvqZmw4yjNzd9Clvj9fj4zEzcly/SVqeLow64H2BHq7MOrbjew+cc5i5xYF3TChK6VclFIblVLblFK7lFKvFrJPV6VUqlJqq+nxUtmEKyq9zk+Csi8wX3qgtwv3d6rNr1uPs+ek/Gcvb79tPc4Lv+6ke6MaTB3RBhdHe4u/Rw0vI6l7uTryn2mb5J5JGSlODf0icIvWuiUQAfRRSrUvZL+1WusI0+M1i0YpbIdXEETeD1tnFZjj5aGb6+Lp7MC7S/ZaMbiqZ13sGf73yzba1fbls3tb4+xg+WR+WYCXC1+PjCQlI4sHpkfLNMpl4IYJXRvOm146mh7WGY0kbEPnJ4yZGPO1pXu7OfJQ13qs3JcoN8/Kyc7jqTz4QzR1/T2YOiKyTGrmV2ta05tJQyPYfjyVp37ZhrUGNtqqYrWhK6XslVJbgQTgT631v4Xs1sHULPOHUqrpdc4zVikVrZSKTkxMLEXYolLzDITIMcZMjElX+qCP6hhOgJczby/ZK//Ry1hCWiZjpm3C29WR7++Pwtu1/KZf6NU0kKd7N2LR9pP8ILNuWlSxErrWOkdrHQGEAFFKqWZX7bIZqGVqlvkE+PU655mqtY7UWkf6+/uXJm5R2XV+HBycYdXbeUWuTvY82bMBW46lsHTXKSsGZ9uycnJ5ZOYWUjOy+HpkW6vMvfJglzp0a+jP6wv3sOtEarm/v60yq5eL1joFWAX0uar83OVmGa31YsBRKVXdUkEKG+RRA6LGwo5fIGFPXvGQ1iHUr+HBu0v2kZWTa8UAbde7S/ay8XAyb93enCY1vawSg52d4v07W1LN3ZFHZ26RqZQtpDi9XPyVUj6m565AD2DvVfsEKtPoA6VUlOm80hAqitZpPDh5wKq38ooc7O14pk8jDp1JZ/amOCsGZ5sWbT/JV2sPM6JDLW5rFWLVWPw8nJk0tBWHk9J5ZcEuq8ZiK4pTQw8CViqltgObMNrQFyqlximlxpn2uQPYqZTaBkwGhmlpBBU34uYL7R+C3b/Bye15xd0b1yAq3JdJy2Ol5mZB+0+nMWHONlqH+fBC/ybWDgeADnX9eLhrXX6JiWflvgRrh1PpyfS5wroyUuDjFhDWEe75Ka9487Gz3P75P4zvXp8nZHrdUkvNyGLwZ3+TlpnNosc6E+BVceYsv5idQ//J67hwMZtlT96Mh7NMAluUoqbPlZGiwrpcfYwFpff/AXGb8opbh1Wjf4sgpq45xKlUGYRSGrm5midnbyUu+QJThreuUMkcwNnBnneGtODkuUze+UPGIZSGJHRhfe3Ggbs/rCg4Hu3ZPo3I0Zp3l8p/8tKYsvogf+1N4MUBTWgb7mvtcArVplY1RnUM54cNR2UcQilIQhfW5+wBN/0PDq+BQ6vyikN93RjTuTbzNh9ne3yK9eKrxHadSGXS8v30bx7EiA61rB1OkSb0bkiorysT5+/gYraMIi0JSeiiYoi8H7xC4K/XIN99nYe71qW6hxOv/b5bBhuZ6WJ2Dk/9vA0fNydeH9ysxNPglhc3JwdeH9ycQ4npTFkli56UhCR0UTE4OEPXZ+F4DOxdlFfs6eLIU70aEn30LIt2nLRigJXPpOWx7D2Vxtu3N6daJVni7+YG/gxsWZPPVx7kQML5Gx8gCpCELiqOlneDXz1Y8TrkXvnKfVdkKI2DvHhr8V6Z0KmYYo4m8+Xqg9wVGUL3xgHWDscsLw5ogoujHc/P3yHfyswkCV1UHPYOcMuLkLjHmOflcrGd4qUBTTieksHUNYeKOIEASMvM4vHZW6np48qLAypGf3Nz+Hs6M7FfY/49nMycmHhrh1OpSEIXFUuTQRDcBla+CVlXuit2qOtH32aBTFl1kJOpGVYMsOJ7ZcFujp/NYNLQCDxdymDSrfOJkLgfzidA9iXLnx8YGhlKm1rVeGfJXlIzssrkPWyRJHRRsSgFPV6Bc/Gw6asCm57r15gcraWvchF+33aCuZvjeaRbPSIt1UXxfCL8PRm+6w/v1oH368FnbeH9+vC6P3zcEv54Fg6thhzLjOy1s1O8OrApSemXmCQrWRWbDMkSFU/tLlC3uzFfeqv7jMFHGN0Yx95Uh09XHuDuqDDa1fGzcqAVy8nUDJ6fv4OIUB8e7V6/9Cc8tQNWvwP7/oDcbAhqCY36g39jcK8OmamQcRbiN0H0t/DvFOMeyC0vGt+0StmrplmwN/e2C2P6+qMMbRtKo0DrTCRWmcjQf1ExndwOX94EnR6HnldWPbxwKZueH67BxdGOxeNvKtMVdioTrTUjvt1I9JGz/DH+JsKru5f8ZBeSYeUbRpJ29oJWw6H1CPBveP1jLqXD/iWw+j3jHkjNVjBgEtSMKHkcQMqFS3R7fxX1AzyZPbZ9he96WR5k6L+ofIJaQIthsGEKpFyZddHoq9yMg4npTF0tN0gv+/HfY6yNPcNz/RuXLpnvWwKftIHo76Dtf+CxLdD7jaKTOYCTOzQbAg/9DYOnQNop+KYnbPqmwLgCc/m4OTGhdyM2Hk7m163HS3yeqkISuqi4bnnB+Nq+4v8KFHdrVIP+zYP4ZOUBDp9Jt1JwFcfRpHTeXLyHm+pXZ3i7sJKdJCcblr8Ks4aCdwiMWwv93jNmxDSHnT1E3APj/obwm2DRkzBvLGSV/Eb20LahtArz4f8W7uFsetnchLUVktBFxeUTCu0fhu2z4cSWAptevrUJzvbSVzknVzPhl+3YK8U7Q1qUrEkiIwVm3AbrPoTWI2HMnxBQ6CqSxefuB/fOgW7PG4uY/HgnXCzZQCF7O8VbtzfnXEYWbyzec+MDqjBJ6KJi6/wEuFWHZS8W+Opew8uFZ/o24p+DSVV6IYxPVxxg45FkXhnYlJo+ruafIO0UfN8fjq6HQZ/BwMngaKHZGO3s4Oan4fapcPQf+OE2449HCTQK9OLBm+swJyaefw6csUx8NkgSuqjYXLyMKQGOrIV9iwtsuicqjPZ1fHlj0Z4q2Td9w6EkPv5rP4MjanJ762DzT5B8CL7tDcmH4Z7Zxs3PstDiLrjze+Nb1vSBRu+YEnj0lvqE+7nx3PwdMmL4OiShi4qvzf3g3wiWPg/ZF/OK7ewU7w5pSXauZuK8qtX0kpx+ifE/baGWnzuv39bc/KaWpIPwbV8juY5cAPW6l02glzUZCMNmwuld8NO9BT7H4nJxtOfN25pzJOkCk/+KLYMgKz9J6KLis3eA3m/C2cNGr5d8wvzceKZPQ1btS6wyw8S11vzvl22cTc/ik7tbmb/CT8oxmD4Ici7BqMUQUmgPOMtr0AsGfW582/r1Icg1fxHwjvWqc2ebEKauOcSek+fKIMjKTRK6qBzqdYcGfY3BRmmnC2wa0SGcqHBfXlu4m+Mptt/08s26w6zYm8Bz/RrRLNjbvIPPnYBpt8LFczDiVwgo57leWg6F7i/Dzrmw/KUSneL5/o3xcXPk2bnbycmtOt/KikMSuqg8er8B2ZnXrGxkZ6f44K6W5OZqnvp5K7k2/J98W1wK7yzZS68mAYzsGG7ewRlnjRuT6UkwfL4x8tMaOj9h9HH/5xPYOsvsw33cnHjp1qZsi09l2j9HLB9fJSYJXVQefnWh/UOw5Udj3vR8Qn3deHlgUzYcSubrdbY54OhcZhaPztpCDU8X3r3DzC6KWZkw6x7jRujdsyCkTdkFeiNKQZ93jH7qCx+/pktqcdzaIohuDf15f9k+4pIvlEGQlZMkdFG5dJkAHgGw6KkCc6YD3NkmhN5NA3h/6X6ba1/V2rjxezwlg8l3R+DjZsaCFbk5MH8sHPsHbvsCat9UdoEWl72D0fPFrTrMvg/SzeuKqJTi9duaY6cUz87bXqVuiBflhgldKeWilNqolNqmlNqllHq1kH2UUmqyUuqAUmq7Uqp12YQrqjwXL6Pp5cQW2DytwCalFG/d3gJvN0cem7WFjEu207VtxoajLNp+kqd6NaBNLTNHb/75Euz+DXq9YQzPryjcq8OwGcY0vHNGX/MH+kaCfVyZ2K8Rfx9IYtbGqjsWIb/i1NAvArdorVsCEUAfpVT7q/bpC9Q3PcYCUxCirDQbYnxdX/6q0R6cj6+7Ex/dFcGBxPO8smCXlQK0rB3xqfzfwj10a+jPuC51zTs45ntY/ylEjYWOj5RJfKVSsxX0/wAOrzZueJvpnqgwOtb1483FezhRBW6I38gNE7o2XB6z62h6XP39ZhAw3bTvBsBHKRVk2VCFMFEK+r0Pl87D8pev2dy5fnUe7lqX2dFx/FbJJ3RKzcjivzM3U93DiQ/visDOzox288NrjKaput2h91tlF2RptRpuTMS26i0jZjMopXj79hbk5Gqembvdpm+IF0ex2tCVUvZKqa1AAvCn1vrfq3YJBvJ/54k3lV19nrFKqWilVHRiYmJJYxYCajQy5nnZ8oMxbP0qT/RoQGStajw3b0elncArx9Rr50RKBp/c09q8hZ6TDhpt03714M7vjDbrikopo5ZevT7M/Y/RBGOGMD83nu/fmLWxZ/hizcEyCrJyKFZC11rnaK0jgBAgSinV7KpdCqs2XPOnUms9VWsdqbWO9Pf3Nz9aIfLr+ix4h8Hvj10z8tDB3o6P726Fg70d436I4fxFy6ykU57eXbKX5XsSePnWJrSpVa34B2amwsyhoOzg7p/Axcy+6tbg7GHcJM1MNWZnNHPQ0b3twhjQIogPlu1n4+HksomxEjCrl4vWOgVYBfS5alM8EJrvdQhwolSRCXEjTu4w4CM4sx/WfnjN5mAfVz67pzUHEs/z+E+Vq3/6L9FxfLnmECM61OK+DuHFPzA3B+aMMUbVDv0BfGuXWYwWF9AU+rwNh1bC+k/MOtS4Id6cMF83Hp21mTPnzZ9awBYUp5eLv1LKx/TcFegBXL2o4wJghKm3S3sgVWt90uLRCnG1+j2g+Z2w9gNIuHat0c71q/Ni/8Ys33OaD/7cZ4UAzffvoSSem7+DzvWq89IAM0dyLn8FDvxpzGUe3rlM4itTbUZB41vhr9euGWtwI54ujnx2T2tSLmTx2KwtZOWYP7VAZVecGnoQsFIptR3YhNGGvlApNU4pNc60z2LgEHAA+Ap4uEyiFaIwvd8yvrL//lihXd9Gdgzn7qhQPlt5kJ+jK3b3tr2nzvHA9GjCfN347J7WONib8SV622z4Z7IxCjNydNkFWZaUglsng0eg8U3jYppZhzep6cWbtzXnn4NJvPq7bfRyMkdxerls11q30lq30Fo301q/Zir/Qmv9hem51lr/V2tdV2vdXGsti4WK8uPhb4w8jPsX1n92zWalFK8ObMZN9avzzNztFbbnS/zZC4z8diOuTvZMGx2Ft5ujGQfHwIJHje6cfd4uuyDLg5svDPkKUo4avXTMNKRNCA92qcOMDceYvv6IxcOryGSkqLANLe6Chv1hxeuFNr04Odgx9b5I2tX25cmft/HHjorVIph0/iIjv93IhUs5TBsdRUg1t+IffO4kzL4XPAPgzmlgb8YfgoqqVkfo8rSxWtW22WYf/nSfRvRoXINXf9/N6v1Vp0edJHRhG5SCWycZN0p/HWeskXkVVyd7vhnZlohQHx6dtaXCJPWEtEzu/moD8Wcz+GpEJI0CvYp/cFYmzB4OmeeMHi3ufmUXaHnrMgHCOhrrkiabNz+PvZ1i0rBW1K/hwUMzYthy7GwZBVmxSEIXtsOjBgz40JgWYN21vV4A3J0d+O7+trQI8eaRWVus3vxyKjWTYVM3EJecwXej2tK+jhkJWWujmeV4NNz+ZenXAa1o7B2M5evsHIz29GzzFoj2cHZg+ugo/D2dGfXdJvafNq89vjKShC5sS9PboNkdsOptOHb1+DeDl4sj08e0I7JWNR6fvZVfrHSj9GDieYZOXc/p1EymjY6iY73q5p1g7Qew42e45QWjZ4gt8gmFQZ/Cic3w1zXTSN1QDS8XZoxph7ODHfd98y/Hkmx7ZkZJ6ML2DPgQvEOMUYfXWZTYw9mB7++PonO96kyYs503F+8p125uK/cmMPjTv0nLzOaH/7QjqraZE27tXgAr/s/osnnT/8omyIqi8a3Q9gFjTpp9f5h9eKivGzP+046L2bnc9eV6DiWev/FBlZQkdGF7XLzhjm8h7QT8Pt5omiiEq5M9X4+MZESHWkxdc4ihX64v8xWPsnNy+XRFLKOnbSLU140Fj3SidZgZo0DBaFKa/yAEt4GBnxj3D2xdr9eNBTnmj4MU879RNQjw5Kex7cnKyeWuLzfYbPOLJHRhm0IijaaI3b9CzHfX3c3ZwZ7XBjXj03tasf/0efpOWsOcmPgymV97y7Gz3Prp37y/bD8DWtRk7kMdzevNAkYymznUmEd82CxwdLV4nBWSo4sxNYDOhTn3m92eDtAo0IvZD7bHTsGwqRtYfzDpxgdVMpLQhe3qOB7q9YDFT0PcxiJ3HdCiJgsf7UzDQE/+98s27v9+k8Vq6wlpmUyct53bp/xDcvpFptzbmsnDInB1sjfvRJmpMPMuo2fLvT8b3RSrEt86MHAyxG+CZS+U6BT1anjy84Md8HF15N6vNzD5r1ibWpdUWWulj8jISB0dLeOPRBm7kAxfdTOS4IOrwTOwyN1zczXT1h/h3SX7yMrJpXezQEa0r0VUbV/zlnwD0jKz+GbdYaauOcSl7Fzu61CLJ3s2wNOlBP3Esy8ayfzIOhg+F+p0Nf8ctmLp80Z7+m1fQsthJTrF+YvZvDB/B79uPUGnen68fXsLQn3N/LZkJUqpGK11ZKHbJKELm3dqJ3zTEwJbwMjfweHG09DGn73A938f4efoOM5lZlPLz43eTQPp3TSAFiE+OBYyJF9rzbHkC/xzMIllu07x98EkLmXn0q95IBN6N6J2dfeSxZ+bY9zg3TUPBk+BiHtKdh5bkZMNPww2aupjlpV4sWutNT9Hx/Ha77vJ0Zrx3Rvwn5tqF/rZWlJ2Ti5ZOdr8b2gmktCF2DnPaHtteQ8M/rzYNxIzLuXw+7YTLNxxkvUHz5CVo3Gyt6NeDQ/qB3jgYGdHdm4uqRlZbI9PJTndaNsN9XWlV5NABkXUpEWIT8nj1hoWT4BNX0HP/4NOj5X8XLbkfCJMvRns7OE/K4zpH0roREoGryzYxbLdp6nr7864m+syKCIYJwfLJvYDCef5JSaOeZuPM6pjOP/tVq9E55GELgTAqndg1ZvGCMRbzG+DTc3IYs3+RHaeSGXvyTQOJp5Ha3C0V7g6OdCsphcRYT5E1vKlQYCH2U00hVrxBqx5Fzo+Br3+r/TnsyXHY+C7/hDYHEYuKPUN4j93n+aDZfvYeyqNQC8X7o4Ko1fTABoFepbos9RaczDxPEt3nWbZ7tNsi0vB3k7RrWEN7u8UTidzxx2YSEIXAq6MrNzyAwyYBJH3Wzuioq1621iWrdVwGPhp1eieaK7dv8HPI6HpYBjyLdiVrlattWZN7BmmrjnIPweT0BpCqrlyU31/2tSqRpta1Qit5nrNLJg5uZqTqRkcS7rA3lNpbD52ls1Hz3IiNROAliHe9GsexG2tg6nh6VKqGCWhC3FZThbMuhsO/mX0VW96m7UjKtzq92Dl6xBxr5HMS5mobNrfk+HPF6HTeOj5msVOm5CWyYo9CSzfc5p/DyeTlmnMD6QUVHNzwsfNkaycXC5czOFcZhZZOVdyabCPK63CfGhXx48ejWsQ5G257qVFJfQKvNCgEGXA3tHozzxjiDE/CFSspK41rHzTaGZpMcwYOCTJvGgdHzVWaPr7Y3DxgZuetMhpa3i6MCwqjGFRYeTmamITzrPl2FlOpmZy5vxFUi5k4eRgh5uTPZ4ujoT5uhHu50bdGh4EeJWuFl5SktBF1ePsAcPnwI93VqyknptjzCwY873RzHLrZOOmnyiaUtDvfWPGyb9eNWbcbPegRd/Czk7RMNCThoGeFj2vpcmfflE1OXvCvb9AaBTMGQ2bvrZuPFkZ8PMII5l3ftLUzCLJvNjs7OG2L4w58f942vg9VkGS0EXV5ewJ986B+r2MlXGWPm/2avMWcfYofNML9i40Vhvq8bLcAC0Je0e48ztjdPDv440mmCpGErqo2pw9YNhMiBprjD6cPRwyynExhIMrjP7UZ4/C3bOh/UPl9962yMHZ+Dyb3g5/vmRMEWCljh/WIAldCDt76Pce9H0XYpfClM7GEPuydOkCLJkIP9wOnkEwdiU07FO271lVODjDkK+NKXf/+cQYUHaxgk2ZW0Z/ZCShC3FZuweNoeQOzvD9AKN2l3nO8u9zZB1M6QgbPoe2Y+A/y8GvruXfpyq7/Ee6x6tGX/WvboHEfdaOCuI2wfRBsGVGmZxeEroQ+QW3gQfXQOsRRu1uciuI/rbQNUrNdmqHMfXt9/0BDSMXQv8PjF4ZwvKUgs6Pw4jfICMZpnYzPktr3Cc5sdX47L/pYfw7UGWTem84sEgpFQpMBwKBXGCq1vrjq/bpCvwGHDYVzdNaF9nDXwYWiQrv+GZY+hwcWw8+YdDmfmh1n3nzhuRkwYHlRo1s70Jj8Y1O46HdOEnk5encCWNRkMNrILSdMVI4oEnZvqfWxgC2vyfD4dXGZ9/xMeOzd/Yo8WlLNVJUKRUEBGmtNyulPIEYYLDWene+fboC/9NaDyhuUJLQRaWgNexdBP9+AUfWgp0j1OoItW+CWp2hWji4+xsLGmsNl9IhNc6Yfz1+I+xfCumJxj6tRxqDYFxLMVmXKDmtYdssozfTxXPG1Ludn7R8c9eFZON9YqbBmX3gEQjtx0HkaCOpl1KpRopqrU8CJ03P05RSe4BgYHeRBwphC5SCxgOMR+I+2DwdDq2CFa/n3wmcveDSedA5V4pdq0H4TcZ0t/V6GN3qhPUoZXwW9XvD6reNz3LrTGgy2Civ07Xkn9GFZNi/BPb8bnwjy7kEwZEw6HNofodxX6YcmDWXi1IqHFgDNNNan8tX3hWYC8QDJzBq67sKOX4sMBYgLCyszdGjR0sRuhBWlJ5k1MDPnYDzp43FqJ09jKHnHgFGW7xfXelPXpGlnTa6qm6eZqwG5VoNGvQxli+s2Rr8G4FTIYteXEqH5MNwZr8xJ/ux9XByu/HH3CsYGg+E1vdBQNMyCdsik3MppTyA1cAbWut5V23zAnK11ueVUv2Aj7XW9Ys6nzS5CCEqhOxLxniAnXOMnxfyrTXq6Abu1cHOwVg1KutCwXEKDi5GTbxWB2jY1/hDUMZ/xEs9OZdSyhGjBv7j1ckcIH9tXWu9WCn1uVKqutb6TEmDFkKIcuHgZIwBaNjHaGdPOWbMtX72CKSfgQtnjMWpHZzBwRW8gqBabWON0xpNirUCVnm5YUJXxszu3wB7tNYfXmefQOC01lorpaIwukPa3pLaQgjbphRUq2U8KqHi1NA7AfcBO5RSW01lzwFhAFrrL4A7gIeUUtlABjBMW2uidSGEqKKK08tlHVBko5DW+lPgU0sFJYQQwnwyUlQIIWyEJHQhhLARktCFEMJGSEIXQggbIQldCCFshCR0IYSwEWbN5WLRN1YqESjpZC7VAVsfhSrXaBvkGm1DRbrGWlrrQudwtlpCLw2lVPT15jKwFXKNtkGu0TZUlmuUJhchhLARktCFEMJGVNaEPtXaAZQDuUbbINdoGyrFNVbKNnQhhBDXqqw1dCGEEFeRhC6EEDai0iV0pVQfpdQ+pdQBpdSz1o7HEpRSoUqplUqpPUqpXUqp8aZyX6XUn0qpWNPPataOtTSUUvZKqS1KqYWm17Z2fT5KqTlKqb2mz7KDDV7jE6Z/ozuVUrOUUi6V/RqVUt8qpRKUUjvzlV33mpRSE035Z59Sqrd1oi5cpUroSil74DOgL9AEuFsp1cS6UVlENvCU1rox0B74r+m6ngX+Mq3P+pfpdWU2HtiT77WtXd/HwBKtdSOgJca12sw1KqWCgceASK11M8AeGEblv8bvgT5XlRV6Tab/l8OApqZjPjflpQqhUiV0IAo4oLU+pLW+BPwEDLJyTKWmtT6ptd5sep6GkQiCMa5tmmm3acBg60RYekqpEKA/8HW+Ylu6Pi+gC8ZyjWitL2mtU7ChazRxAFyVUg6AG3CCSn6NWus1QPJVxde7pkHAT1rri1rrw8ABjLxUIVS2hB4MxOV7HW8qsxlKqXCgFfAvEKC1PglG0gdqWC+yUpsEPA3k5iuzpeurAyQC35malb5WSrljQ9eotT4OvA8cA04CqVrrZdjQNeZzvWuq0DmosiX0wpbCs5l+l0opD2Au8LjW+py147EUpdQAIEFrHWPtWMqQA9AamKK1bgWkU/maHopkakceBNQGagLuSqnh1o2q3FXoHFTZEno8EJrvdQjGV75KTynliJHMf9RazzMVn1ZKBZm2BwEJ1oqvlDoBA5VSRzCayW5RSs3Adq4PjH+b8Vrrf02v52AkeFu6xh7AYa11otY6C5gHdMS2rvGy611Thc5BlS2hbwLqK6VqK6WcMG5OLLByTKWmlFIYba97tNYf5tu0ABhpej4S+K28Y7MErfVErXWI1joc4zNbobUejo1cH4DW+hQQp5RqaCrqDuzGhq4Ro6mlvVLKzfRvtjvG/R5busbLrndNC4BhSilnpVRtoD6w0QrxFU5rXakeQD9gP3AQeN7a8VjomjpjfG3bDmw1PfoBfhh32GNNP32tHasFrrUrsND03KauD4gAok2f469ANRu8xleBvcBO4AfAubJfIzAL455AFkYNfExR1wQ8b8o/+4C+1o4//0OG/gshhI2obE0uQgghrkMSuhBC2AhJ6EIIYSMkoQshhI2QhC6EEDZCEroQQtgISehCCGEj/h9GR7IOATDWQAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving cache!\n",
      "Current primitives:\n",
      "{'epoch_i': 107, 'loss-history': [[56415029850.35294, 56361540547.76471, 56311842454.588234, 56256060114.82353, 56191308137.411766, 56117140058.35294, 56032325029.64706, 55933626849.882355, 55819893940.70588, 55687923952.94118, 55535569136.94118, 55355938816.0, 55145878708.70588, 54907567887.05882, 54640776854.588234, 54344956747.29412, 54016731497.411766, 53652801174.588234, 53256027316.70588, 52821646757.64706, 52343608982.588234, 51829835053.17647, 51277340431.05882, 50685483610.35294, 50061168158.117645, 49400745863.52941, 48710108461.17647, 47983253142.588234, 47220476024.47059, 46417181635.76471, 45590633773.17647, 44739568218.35294, 43866681103.05882, 42982413372.23529, 42083269330.82353, 41175785110.588234, 40262188815.05882, 39351686264.47059, 38441706375.52941, 37540321520.94118, 36648048278.588234, 35769302678.588234, 34915846505.411766, 34076255232.0, 33271828359.52941, 32482350260.705883, 31753824075.294117, 31065152692.705883, 30414478396.235294, 29797723557.64706, 29243499760.941177, 28773970100.705883, 28332841140.705883, 27989771264.0, 27688720082.82353, 27497599397.64706, 27352786763.294117, 27270752015.058823, 27279345965.17647, 27378395497.411766, 27520328944.941177, 27769951713.882355, 28051091576.47059, 28419878610.82353, 28863351506.82353, 29368963614.117645, 29914663755.294117, 30517961547.294117, 31136415864.47059, 31752897536.0, 32423653135.058823, 33065830159.058823, 33733396118.588234, 34309175296.0, 34892214452.70588, 35401500129.882355, 35847297807.05882, 36190022415.05882, 36455714695.52941, 36595936557.17647, 36619603847.52941, 36518517880.47059, 36293694162.82353, 35967218206.117645, 35506766305.882355, 34966254290.82353, 34346959872.0, 33646873720.47059, 32919510317.17647, 32152761163.294117, 31432529558.588234, 30717200384.0, 30025774320.941177, 29421976576.0, 28874956559.058823, 28383652502.588234, 27942878991.058823, 27602186420.705883, 27318530288.941177, 27108815269.64706, 26968677436.235294, 26864294912.0, 26824614731.294117, 26846001453.17647, 26910288293.64706, 27012505419.294117, 27154586563.764706, 27328957620.705883], [55127897429.333336, 55076268032.0, 55025384789.333336, 54965839872.0, 54897345877.333336, 54818699946.666664, 54728232960.0, 54623592448.0, 54502432085.333336, 54362089472.0, 54198022826.666664, 54005141504.0, 53783185408.0, 53533407232.0, 53254709248.0, 52945609386.666664, 52603942229.333336, 52227454293.333336, 51814465536.0, 51362581162.666664, 50870779221.333336, 50341084501.333336, 49772750165.333336, 49168039936.0, 48529605973.333336, 47858272938.666664, 47152585386.666664, 46410218837.333336, 45628652202.666664, 44814586538.666664, 43974649856.0, 43112826880.0, 42232610816.0, 41337065472.0, 40429623296.0, 39513610240.0, 38592620544.0, 37670091434.666664, 36749892949.333336, 35835862357.333336, 34932150954.666664, 34042821632.0, 33171850581.333332, 32323673088.0, 31502201514.666668, 30711896746.666668, 29956251648.0, 29239520597.333332, 28566434474.666668, 27942060714.666668, 27370586112.0, 26855218176.0, 26400053589.333332, 26007858517.333332, 25681808384.0, 25423905792.0, 25236308650.666668, 25120480597.333332, 25076970496.0, 25105835349.333332, 25206248106.666668, 25376717482.666668, 25614326442.666668, 25915454464.0, 26275607210.666668, 26689172480.0, 27149063850.666668, 27647988053.333332, 28176698368.0, 28724071765.333332, 29281530197.333332, 29836651520.0, 30379024725.333332, 30891531264.0, 31363321514.666668, 31780501162.666668, 32130143914.666668, 32396539904.0, 32573933568.0, 32649628330.666668, 32618944853.333332, 32480627029.333332, 32237629440.0, 31889983146.666668, 31452712618.666668, 30939671552.0, 30367545002.666668, 29757897045.333332, 29129450496.0, 28502817792.0, 27893481472.0, 27316719274.666668, 26785713152.0, 26308490240.0, 25891611648.0, 25539395584.0, 25253644629.333332, 25033530368.0, 24877329749.333332, 24782020949.333332, 24743853056.0, 24758541312.0, 24821419690.666668, 24927788373.333332, 25072954026.666668, 25252304554.666668, 25461465429.333332, 25696294912.0]]}\n",
      "Saving cache!\n",
      "Current primitives:\n",
      "{'epoch_i': 108, 'loss-history': [[56415029850.35294, 56361540547.76471, 56311842454.588234, 56256060114.82353, 56191308137.411766, 56117140058.35294, 56032325029.64706, 55933626849.882355, 55819893940.70588, 55687923952.94118, 55535569136.94118, 55355938816.0, 55145878708.70588, 54907567887.05882, 54640776854.588234, 54344956747.29412, 54016731497.411766, 53652801174.588234, 53256027316.70588, 52821646757.64706, 52343608982.588234, 51829835053.17647, 51277340431.05882, 50685483610.35294, 50061168158.117645, 49400745863.52941, 48710108461.17647, 47983253142.588234, 47220476024.47059, 46417181635.76471, 45590633773.17647, 44739568218.35294, 43866681103.05882, 42982413372.23529, 42083269330.82353, 41175785110.588234, 40262188815.05882, 39351686264.47059, 38441706375.52941, 37540321520.94118, 36648048278.588234, 35769302678.588234, 34915846505.411766, 34076255232.0, 33271828359.52941, 32482350260.705883, 31753824075.294117, 31065152692.705883, 30414478396.235294, 29797723557.64706, 29243499760.941177, 28773970100.705883, 28332841140.705883, 27989771264.0, 27688720082.82353, 27497599397.64706, 27352786763.294117, 27270752015.058823, 27279345965.17647, 27378395497.411766, 27520328944.941177, 27769951713.882355, 28051091576.47059, 28419878610.82353, 28863351506.82353, 29368963614.117645, 29914663755.294117, 30517961547.294117, 31136415864.47059, 31752897536.0, 32423653135.058823, 33065830159.058823, 33733396118.588234, 34309175296.0, 34892214452.70588, 35401500129.882355, 35847297807.05882, 36190022415.05882, 36455714695.52941, 36595936557.17647, 36619603847.52941, 36518517880.47059, 36293694162.82353, 35967218206.117645, 35506766305.882355, 34966254290.82353, 34346959872.0, 33646873720.47059, 32919510317.17647, 32152761163.294117, 31432529558.588234, 30717200384.0, 30025774320.941177, 29421976576.0, 28874956559.058823, 28383652502.588234, 27942878991.058823, 27602186420.705883, 27318530288.941177, 27108815269.64706, 26968677436.235294, 26864294912.0, 26824614731.294117, 26846001453.17647, 26910288293.64706, 27012505419.294117, 27154586563.764706, 27328957620.705883, 27523635862.588234], [55127897429.333336, 55076268032.0, 55025384789.333336, 54965839872.0, 54897345877.333336, 54818699946.666664, 54728232960.0, 54623592448.0, 54502432085.333336, 54362089472.0, 54198022826.666664, 54005141504.0, 53783185408.0, 53533407232.0, 53254709248.0, 52945609386.666664, 52603942229.333336, 52227454293.333336, 51814465536.0, 51362581162.666664, 50870779221.333336, 50341084501.333336, 49772750165.333336, 49168039936.0, 48529605973.333336, 47858272938.666664, 47152585386.666664, 46410218837.333336, 45628652202.666664, 44814586538.666664, 43974649856.0, 43112826880.0, 42232610816.0, 41337065472.0, 40429623296.0, 39513610240.0, 38592620544.0, 37670091434.666664, 36749892949.333336, 35835862357.333336, 34932150954.666664, 34042821632.0, 33171850581.333332, 32323673088.0, 31502201514.666668, 30711896746.666668, 29956251648.0, 29239520597.333332, 28566434474.666668, 27942060714.666668, 27370586112.0, 26855218176.0, 26400053589.333332, 26007858517.333332, 25681808384.0, 25423905792.0, 25236308650.666668, 25120480597.333332, 25076970496.0, 25105835349.333332, 25206248106.666668, 25376717482.666668, 25614326442.666668, 25915454464.0, 26275607210.666668, 26689172480.0, 27149063850.666668, 27647988053.333332, 28176698368.0, 28724071765.333332, 29281530197.333332, 29836651520.0, 30379024725.333332, 30891531264.0, 31363321514.666668, 31780501162.666668, 32130143914.666668, 32396539904.0, 32573933568.0, 32649628330.666668, 32618944853.333332, 32480627029.333332, 32237629440.0, 31889983146.666668, 31452712618.666668, 30939671552.0, 30367545002.666668, 29757897045.333332, 29129450496.0, 28502817792.0, 27893481472.0, 27316719274.666668, 26785713152.0, 26308490240.0, 25891611648.0, 25539395584.0, 25253644629.333332, 25033530368.0, 24877329749.333332, 24782020949.333332, 24743853056.0, 24758541312.0, 24821419690.666668, 24927788373.333332, 25072954026.666668, 25252304554.666668, 25461465429.333332, 25696294912.0, 25952721920.0]]}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [22]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mrunner\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mshow_freq\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/myprojects/ML-Mnemonist/mlmnemonist/experiment_runner.py:121\u001B[0m, in \u001B[0;36mExperimentRunner.run\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    119\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrecurring_pipeline\u001B[38;5;241m.\u001B[39mrun(keep\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose, runner\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m    120\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mCACHE\u001B[38;5;241m.\u001B[39m_load_cache()\n\u001B[0;32m--> 121\u001B[0m ret \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_implemented_run\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    123\u001B[0m \u001B[38;5;66;03m# Save configurations\u001B[39;00m\n\u001B[1;32m    124\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcfg \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "Input \u001B[0;32mIn [21]\u001B[0m, in \u001B[0;36mmy_custom_run\u001B[0;34m(runner, show_freq)\u001B[0m\n\u001B[1;32m     33\u001B[0m loss_train \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     34\u001B[0m my_model\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[0;32m---> 35\u001B[0m \u001B[43mhelper\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmy_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrunner\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_X\u001B[49m\u001B[43m[\u001B[49m\u001B[43minds\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     36\u001B[0m \u001B[43m       \u001B[49m\u001B[43mrunner\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_Y\u001B[49m\u001B[43m[\u001B[49m\u001B[43minds\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrunner\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     37\u001B[0m \u001B[43m       \u001B[49m\u001B[43mrunner\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrunner\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptim\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     38\u001B[0m loss_history[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28msum\u001B[39m(loss_train) \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mlen\u001B[39m(loss_train))\n\u001B[1;32m     40\u001B[0m loss_test \u001B[38;5;241m=\u001B[39m []\n",
      "Input \u001B[0;32mIn [21]\u001B[0m, in \u001B[0;36mhelper\u001B[0;34m(model, X, y, history, device, loss_fn, optimizer)\u001B[0m\n\u001B[1;32m      8\u001B[0m en \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmin\u001B[39m(st \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m500\u001B[39m, X\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m      9\u001B[0m X_ \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mfrom_numpy(X[st:en, :])\u001B[38;5;241m.\u001B[39mfloat()\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m---> 10\u001B[0m pred \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m y_ \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mfrom_numpy(y[st:en])\u001B[38;5;241m.\u001B[39mfloat()\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     12\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss_fn(pred\u001B[38;5;241m.\u001B[39msqueeze(), y_)\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Input \u001B[0;32mIn [15]\u001B[0m, in \u001B[0;36mMyMLP.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[0;32m---> 13\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43ml1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     14\u001B[0m     x \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mrelu(x)\n\u001B[1;32m     15\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39ml2(x)\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py:103\u001B[0m, in \u001B[0;36mLinear.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    102\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 103\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "runner.run(show_freq=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-AqjwHsjpML"
   },
   "source": [
    "# Run even after the session is closed\n",
    "\n",
    "Each runner has a cache token associated with it. You can checkout your runner's token using the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "OSKZn4j_jrmH",
    "outputId": "1dcbf48e-5a07-4b5f-db50-17d2e614723f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'tok-227'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runner.CACHE.TOKEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M6sVSjy_j5hh"
   },
   "source": [
    "Now re-run your session and when you are creating a runner use the token in the `cache_token=YOUR_TOKEN` variable. That way, when you call `load_cache()` or whenever you re-run the `run()` function. All the variables that have been cached will be reloaded again."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "ExperimentRunnerTutorial.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}