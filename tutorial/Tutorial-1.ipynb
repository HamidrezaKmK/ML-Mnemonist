{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/HamidrezaKmK/ML-Mnemonist/blob/main/ExperimentRunnerTutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The following set of instructions can be used to setup a hosted runtime. Hosted runtimes on Colab might be unreliable and get shut down after using for a while, deleting all the progress in the process. That said, in the following we will go through a simple example of using ML-Mnemonist to our advantage. In the following, we address a simple regression task and try to train a neural network created by PyTorch to fit the data. In the midst of the experiment, we can interrupt the training process and restart the runtime. All the data in the runtime will be stored in a specific format in certain directories specified in the `.env` file. Using the cached directories, we can resume our progress seamlessly after restarting the runtime and loading it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rE6olttuFV0Q",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Setup hosted runtime\n",
    "\n",
    "Set of instructions used to clone the ML-Mnemonist repository. This block is created for Colab users. The first block creates an executable and the second one runs the executable and installs pre-requisites of the project. The process is done in the following manner:\n",
    "1. The Google drive is mounted.\n",
    "2. The ML-Mnemonist repository is cloned (or pulled, depends on your response).\n",
    "3. The `.env` directory is a personal file and you should specify it yourself. You can either enter the content of the file line by line or specify a directory (presumably from your Google drive) to copy into the cloned repository -- This will help setup the ML-Mnemonist base directories such as the experiments directory, the configurations directory, the secret directory, and caching directory.\n",
    "4. Afterward, you are prompted to install packages, these packages are specified in the cloned repository's `requirement.txt` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eOfp_NGbT1jZ",
    "outputId": "79649df5-19a7-4f4a-a2a6-f49a6cc498c7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "% % writefile sys_setup.py\n",
    "#!usr/bin/bash python\n",
    "\n",
    "import sys\n",
    "from google.colab import drive\n",
    "import subprocess\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "PROJ_NAME = 'ML-Mnemonist'\n",
    "GIT_DIR = 'HamidrezaKmK'\n",
    "\n",
    "data_dir = None\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    env = os.environ.copy()\n",
    "    if not os.path.exists('/content/drive'):\n",
    "        print(\"Mounting drive...\")\n",
    "        drive.mount('/content/drive')\n",
    "        print(\"Mount complete!\")\n",
    "\n",
    "    while True:\n",
    "        opt = input(\"What are you trying to do? [clone/pull] \")\n",
    "        if opt == 'clone':\n",
    "            addr = f\"https://github.com/{GIT_DIR}/{PROJ_NAME}\"\n",
    "            print(f\"Trying to connect to {addr}\")\n",
    "            token = input(\"Enter token: \")\n",
    "            addr = addr.replace('[TOKEN]', token)\n",
    "            res = subprocess.run(['git', 'clone', addr], env=env, capture_output=True)\n",
    "            print(res.stdout.decode())\n",
    "            print(res.stderr.decode())\n",
    "            break\n",
    "        elif opt == 'pull':\n",
    "            path = os.path.join('/content', PROJ_NAME)\n",
    "            os.chdir(path)\n",
    "            res = subprocess.run(['git', 'pull'], env=env, capture_output=True)\n",
    "            print(res.stdout.decode())\n",
    "            print(res.stderr.decode())\n",
    "            break\n",
    "        elif opt == '':\n",
    "            print(\"Nothing happened!\")\n",
    "            break\n",
    "\n",
    "    if not os.path.exists(f'/content/{PROJ_NAME}'):\n",
    "        raise RuntimeError(\"No project repository available!\")\n",
    "\n",
    "    if not os.path.exists(f'/content/{PROJ_NAME}/.env'):\n",
    "        print(\"Dotenv non-existant!\")\n",
    "        while True:\n",
    "            resp = input(\"Do you want to enter the file in the prompt or copy it?\\n[copy/write] \")\n",
    "            if resp == 'copy':\n",
    "                dir = input(\"Enter the directory to copy: \")\n",
    "                shutil.copyfile(dir, f'/content/{PROJ_NAME}/.env')\n",
    "            elif resp == 'write':\n",
    "                print(\"Enter the lines in format ENV_VARIABLE_NAME=VALUE\")\n",
    "                print(\"End with: ENDFILE\")\n",
    "                with open(f'/content/{PROJ_NAME}/.env', 'w') as f:\n",
    "                    while True:\n",
    "                        line = input()\n",
    "                        if line == 'ENDFILE':\n",
    "                            break\n",
    "                        f.write(f'{line}\\n')\n",
    "            else:\n",
    "                continue\n",
    "            break\n",
    "\n",
    "    os.chdir('/content')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "mzkBQqSLUWC3",
    "outputId": "2d475291-ff6f-430d-da51-06a1eb22bb66",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "PROJ_NAME = 'ML-Mnemonist'\n",
    "\n",
    "from IPython.display import clear_output\n",
    "% run / content / sys_setup.py\n",
    "resp = input(\"Do you want to install packages? [y/n] \")\n",
    "if resp == 'y':\n",
    "    !pip install -r / content / ML-Mnemonist / requirements.txt\n",
    "    input(\"Requrements installed! -- press any key to continue ...\")\n",
    "clear_output()\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(f'/content/{PROJ_NAME}')\n",
    "os.chdir(f'/content/{PROJ_NAME}')\n",
    "print(\"Running complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Local Runtime\n",
    "\n",
    "In case you want to run the tutorial on a local machine you should make sure to include the `mlmnemonist` directory in your `sys.path` using `sys.path.append(ROOT)`; this assumes you have cloned the repository and want to run from source codes. Otherwise, you can also run `pip install mlmnemonist` and proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Using the repository source (If you have not yet installed the package)\n",
    "%load_ext autoreload\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dotenv\n",
    "\n",
    "The dotenv for this tutorial should look like the following:\n",
    "\n",
    "```\n",
    "MLM_EXPERIMENT_DIR=\"absolute-path-to-testing\"\n",
    "MLM_CONFIG_DIR=\"absolute-path-to-testing/config\"\n",
    "MLM_CHECKPOINT_DIR=\"absolute-path-to-testing\"\n",
    "MLM_SECRET_ROOT_DIR=\"absolute-path-to-testing\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iNiIuYQbWti3",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Experiment runner\n",
    "\n",
    "After ensuring everything is set to the wanted values in `.env`, use the object `FACTORY` to create an experiment runner. You can print an experiment runner to get an overview of the functions it is using as well as its corresponding experiment directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%autoreload 3\n",
    "import mlmnemonist as mlm\n",
    "my_runner = mlm.FACTORY.create_experiment_runner(description='This is an experiment runner created only for the purpose of testing',\n",
    "                                                 experiment_name='tut1')\n",
    "print(my_runner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_FxBXOOvtLWC",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now, we will create an experiment that takes in a configuration node defined in the `CfgNode` class of `yaccs`. Run the following block that uses a configuration default drawn from the testing directory. This configuration file is defined for a simple problem that we delve into in the next section. For now, we want to draw your attention on how to use the `cfg_base` and `cfg_dir` arguments to define a specific configuration for experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "azqIcguUWxka",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from testing.config.config import get_cfg_defaults\n",
    "%autoreload 3\n",
    "\n",
    "\n",
    "runner = mlm.FACTORY.create_experiment_runner(\"tut-with-config\",\n",
    "                                              description=\"This is an experiment that takes in a configuration\",\n",
    "                                              cfg_base=get_cfg_defaults())\n",
    "print(\"-----------------------\")\n",
    "print(\"Default configurations:\")\n",
    "print(\"-----------------------\")\n",
    "print(runner.get_cfg())\n",
    "print(runner)\n",
    "\n",
    "# Now use an additional configuration file and merge it with the previous\n",
    "runner = mlm.FACTORY.create_experiment_runner(\"tut-with-config\",\n",
    "                                              description=\"This is an experiment that takes in a configuration\",\n",
    "                                              cfg_base=get_cfg_defaults(),\n",
    "                                              cfg_dir='conf-test.yaml')\n",
    "print(\"------------------------\")\n",
    "print(\"Configurations from yaml:\")\n",
    "print(\"------------------------\")\n",
    "print(runner.get_cfg())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we can also retrieve the previous runner we defined using the retrieve functionality in the factory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Eh4tGm5XTOR",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%autoreload 3\n",
    "runner = mlm.FACTORY.retrieve_experiment_runner('0')\n",
    "print(runner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U_PEvAX89xMs",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Run a simple linear regression program\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we try to solve the classic house pricing regression problem. The data is available in `testing/data` directory. Two `csv` files are available with columns presenting different features of the house and a column indicating their price. The goal is to train a neural network model using the training dataset and then test it on the test dataset.\n",
    "\n",
    "We will first define a new runner and fill up the different sections of the pipeline. The preprocess pipeline of the runner consists of two functions:\n",
    "1. `load_raw_data`: Read the csv files into appropriate pandas dataframes.\n",
    "2. `process_data`: Convert the dataframes into numpy arrays.\n",
    "\n",
    "Each time we call the `run` function for the model - either after a session has crashed or after pausing - a set of functions repeat and we fit them in the `recurring_pipeline` category. For this problem, this is categorized in the following:\n",
    "1. `setup_device`: Using the config file, figure out the device being used. The device can either be `cpu` or `cuda`.\n",
    "2. `setup_model`: Create a multi-layer perceptron model and set the device associated with the model appropriately.\n",
    "3. `setup_training`: Setup the optimizer that is being used for the training, the loss function, and other things that are required pre-training.\n",
    "\n",
    "Note that in the implementation below, we have defined variables such as `runner.device`, `runner.optim`, and `runner.criterion` that is being used accross the experiment runner pipeline. This scheme can be repeated for any other variable that might re-accure accross preprocessing, recurring_pipeline, or the run function itself.\n",
    "\n",
    "Before we delve into the implentations, we should go through the configurations that have been set for this problem. The config file available in `conf-test.yaml` contains three sections. First off, the `DATASET` section contains two directories indicating the raw csv file directories that contain the house features and their prices. Secondly, the `SOLVER` section contains information while training such as the learning rate, the optimizer being used, whether we use cuda or cpu, and the type of model (here being Multi-layer perceptrons). Finally, the last section relates to the model hyper-parameters which contain the input feature size and the hidden layer sizes.\n",
    "\n",
    "**Note**: We can also adjust how frequent the experiment runner prints out logs using the `verbose` statement. Here we have set it to 1 and this results in some minor logs being produced while calling `runner.preprocess()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GFRWSI6F_Af_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%autoreload 3\n",
    "import mlmnemonist as mlm\n",
    "from testing.config.config import get_cfg_defaults\n",
    "from mlmnemonist.experiment_runner import ExperimentRunner\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "runner = mlm.FACTORY.create_experiment_runner('regress-houses',\n",
    "                                              description='This experiments trains a model to do a regression on the house pricing task',\n",
    "                                              cfg_base=get_cfg_defaults(),\n",
    "                                              cfg_dir='conf-test.yaml',\n",
    "                                              verbose=1\n",
    "                                              )\n",
    "print(runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "PhuvzGFG-86Z",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_raw_data(runner: ExperimentRunner):\n",
    "    train_name = runner.cfg.DATASET.TRAIN_NAME\n",
    "    test_name = runner.cfg.DATASET.TEST_NAME\n",
    "    runner.train_df = pd.read_csv(runner.reveal_true_path(train_name))\n",
    "    runner.test_df = pd.read_csv(runner.reveal_true_path(test_name))\n",
    "\n",
    "\n",
    "runner.preprocessing_pipeline.update_function(load_raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "3Vo6EsKg_jmk",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def process_data(runner: ExperimentRunner):\n",
    "    runner.train_X = runner.train_df.drop(columns='median_house_value').to_numpy()\n",
    "    runner.train_Y = runner.train_df['median_house_value'].to_numpy()\n",
    "    runner.test_X = runner.test_df.drop(columns='median_house_value').to_numpy()\n",
    "    runner.test_Y = runner.test_df['median_house_value'].to_numpy()\n",
    "\n",
    "\n",
    "runner.preprocessing_pipeline.update_function(process_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o9XySh8pBGwz",
    "outputId": "279a1b1d-764f-4e9b-a8c5-a53d936e709e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Run the functions one-by-one in order they have been added in the `update_function` method\n",
    "runner.preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dXriKjd6IaYC",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Create a model using configurations\n",
    "\n",
    "The following introduces a simple class of a custom multi-layer perceptron. We then implement the recurring pipeline of the runner and add the corresponding functions by the `update_function` method on the `recurring_pipeline`. Note that the recurring pipeline contains a set of functions that will run each time we call the `runner.run()` method. Note that in the implementation of `setup_model` we have used the `runner.CACHE` which contains the cached information to cache the model parameters. The model parameters should be cached in iterations because we do not want to lose our training progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "4rUEXYL2p-Jx",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class MyMLP(nn.Module):\n",
    "    \"\"\"\n",
    "    A self explanatory MLP model with ReLU activations and 2 hidden layers\n",
    "    \"\"\"\n",
    "    def __init__(self, input_features: int, hidden_layer_1: int, hidden_layer_2: int):\n",
    "        super(MyMLP, self).__init__()\n",
    "        self.l1 = nn.Linear(input_features, hidden_layer_1)\n",
    "        self.l2 = nn.Linear(hidden_layer_1, hidden_layer_2)\n",
    "        self.l3 = nn.Linear(hidden_layer_2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.l2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.l3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "2DdIqwaOSRlR",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def setup_device(runner: ExperimentRunner):\n",
    "    # extract the device from config\n",
    "    device = runner.cfg.SOLVER.DEVICE\n",
    "    if device == 'cpu':\n",
    "        runner.device = torch.device('cpu')\n",
    "    elif device == 'cuda' and torch.cuda.is_available():\n",
    "        runner.device = torch.device('cuda')\n",
    "    else:\n",
    "        raise NotImplementedError(f\"device {device} is not implemented!\")\n",
    "\n",
    "\n",
    "runner.recurring_pipeline.update_function(setup_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ort8OLJRIeUQ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def setup_model(runner: ExperimentRunner):\n",
    "    # extract the method from config\n",
    "    method = runner.cfg.SOLVER.METHOD\n",
    "    # construct the model from registry\n",
    "    cfg_h_params = runner.cfg.MODEL.HYPER_PARAMETERS\n",
    "    my_model = MyMLP(input_features=cfg_h_params.IN_FEATURES,\n",
    "                     hidden_layer_1=cfg_h_params.H1,\n",
    "                     hidden_layer_2=cfg_h_params.H2)\n",
    "    # set the function in the cache to save weights\n",
    "    my_model = runner.CACHE.SET_M('mlp-key', my_model)\n",
    "    my_model.to(runner.device)\n",
    "    if runner.verbose > 0:\n",
    "        print(\"Model state dict\")\n",
    "        print(my_model)\n",
    "\n",
    "\n",
    "runner.recurring_pipeline.update_function(setup_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "sGhQ3LKcS-dC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def setup_training(runner: ExperimentRunner):\n",
    "    my_model = runner.CACHE.GET_M('mlp-key').to(runner.device)\n",
    "    runner.criterion = nn.MSELoss()\n",
    "    if runner.cfg.SOLVER.OPTIMIZER_TYPE == 'adam':\n",
    "        runner.optim = torch.optim.Adam(my_model.parameters(), lr=runner.cfg.SOLVER.LR)\n",
    "    else:\n",
    "        raise NotImplementedError(f\"Optimizer type not implemented\"\n",
    "                                  f\"{runner.cfg.SOLVER.OPTIMIZER_TYPE}\")\n",
    "\n",
    "\n",
    "runner.recurring_pipeline.update_function(setup_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we output the runner it will contain the function names of the recurring and the preprocessing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m3H9fjChzRRF",
    "outputId": "17f0f93e-66cd-4785-bfa7-99db66b52d8b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(runner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57mO42YpH-Ck",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Implement a run function\n",
    "\n",
    "A run function is the core part of an experiment. This function takes in an input of type `ExperimentRunner` type is its first element and a bunch of arbitrary input types for the rest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ajq3MZ0bhlxG",
    "outputId": "05c1c2ab-bf36-49b1-9cda-c9f1ff1f8abc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Using the following you can revert all that has been done in the previous runs\n",
    "# By default, this function prompts you to check whether your are sure or not\n",
    "# Using prompt=False you can remove that condition\n",
    "runner.CACHE.RESET()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "0il8pIX8H_uz",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def my_custom_run(runner: ExperimentRunner, show_freq=50):\n",
    "    # Get model from cache\n",
    "    my_model = runner.CACHE.GET_M('mlp-key')\n",
    "\n",
    "    # Get the epoch number and history from cache\n",
    "    # if it is not cached from before set it to zero\n",
    "    epoch_i = runner.CACHE.SET_IFN('epoch_i', 0)\n",
    "    loss_history = runner.CACHE.SET_IFN('loss-history', {'train': [], 'test': []})\n",
    "    for epoch_i in range(epoch_i, 1000):\n",
    "\n",
    "        # Shuffle all the indices first\n",
    "        inds = np.arange(runner.train_X.shape[0])\n",
    "        np.random.shuffle(inds)\n",
    "\n",
    "        batch_size = runner.cfg.SOLVER.BATCH_SIZE\n",
    "\n",
    "        loss_train = []\n",
    "        my_model.train()\n",
    "        for L in range(0, runner.train_X.shape[0], batch_size): \n",
    "            R = min(L + batch_size, runner.train_X.shape[0])\n",
    "            # Find the range [L:R]\n",
    "            X = torch.from_numpy(runner.train_X[inds[L:R],:]).float().to(runner.device)\n",
    "            y = torch.from_numpy(runner.train_Y[inds[L:R]]).float().to(runner.device)\n",
    "            loss = runner.criterion(my_model(X).squeeze(), y)\n",
    "            # Find the loss between the predicted batch and y\n",
    "            loss.backward()\n",
    "            runner.optim.step()\n",
    "            loss_train.append(loss.detach().cpu().item())\n",
    "\n",
    "        # Find the average loss and add it to the trainign loss history\n",
    "        mean_loss = sum(loss_train) / len(loss_train)\n",
    "        loss_history['train'].append(mean_loss)\n",
    "\n",
    "        # Now we will check the loss on the whole test dataset\n",
    "        loss_test = []\n",
    "        # Shuffle all the indices first\n",
    "        inds = np.arange(runner.test_X.shape[0])\n",
    "        np.random.shuffle(inds)\n",
    "        my_model.eval()\n",
    "        with torch.no_grad():\n",
    "            for L in range(0, runner.test_X.shape[0], batch_size):\n",
    "                R = min(L + batch_size, runner.test_X.shape[0])\n",
    "                X = torch.from_numpy(runner.test_X[inds[L:R], :]).float().to(runner.device)\n",
    "                y = torch.from_numpy(runner.test_Y[inds[L:R]]).float().to(runner.device)\n",
    "                loss = runner.criterion(my_model(X).squeeze(), y)\n",
    "                loss_test.append(loss.detach().cpu().item())\n",
    "        # Find the average loss and add them to loss history\n",
    "        mean_loss = sum(loss_test) / len(loss_test)\n",
    "        loss_history['test'].append(mean_loss)\n",
    "\n",
    "\n",
    "        # Display the losses\n",
    "        if (epoch_i + 1) % show_freq == 0:\n",
    "            clear_output()\n",
    "            plt.plot(list(range(len(loss_history['train']))), loss_history['train'], label='loss-train')\n",
    "            plt.plot(list(range(len(loss_history['test']))), loss_history['test'], label='loss-test')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "        # Caching and saving checkpoints\n",
    "        runner.CACHE.SET('epoch_i', epoch_i)\n",
    "        runner.CACHE.SET('loss-history', loss_history)\n",
    "        runner.CACHE.SET_M('mlp-key', my_model)\n",
    "        runner.CACHE.SAVE()\n",
    "\n",
    "\n",
    "# The following sets the `my_custom_run` fuction as the function which \n",
    "# will be called after each time the runner.run() method is called\n",
    "runner.implement_run(my_custom_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cc8aGQq_jDAG",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Run the following function to see the training and validation loss.\n",
    "Interrupt the process for as many times as you like and re-run it. Since the code supports caching, it will continue right off where it last ended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "p6IKYVw7dKBo",
    "outputId": "a3436114-2c4a-4dc5-a453-c82cb8b413eb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "runner.run(show_freq=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-AqjwHsjpML",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Run even after the session is closed\n",
    "\n",
    "Each runner has a cache token associated with it. You can checkout your runner's token using the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "OSKZn4j_jrmH",
    "outputId": "1dcbf48e-5a07-4b5f-db50-17d2e614723f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "runner.CACHE.TOKEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M6sVSjy_j5hh",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now restart the session and then use the factory retrieve function using the cache token above. That way, when you call `load_cache()` or whenever you re-run the `run()` function all the variables that have been cached will be reloaded again. \n",
    "\n",
    "**Note:** If you have used certain functions in the preprocessing or recurring pipeline, you should define them again in the session; otherwise, you might get errors where a function source code is cached but it has not yet been defined in your environment. This means that if you restart the session you have to re-run all the blocks containing the definitions of functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlmnemonist as mlm\n",
    "\n",
    "runner = mlm.FACTORY.retrieve_experiment_runner('4')\n",
    "runner.preprocess()\n",
    "runner.run(show_freq=50)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "ExperimentRunnerTutorial.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "ef0468b6e6b9a4e1c076af9f1e41a9e6221f7ddc2a937addc4d954af369e1a55"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
