{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/HamidrezaKmK/ML-Mnemonist/blob/main/ExperimentRunnerTutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rE6olttuFV0Q"
   },
   "source": [
    "# Setup hosted runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eOfp_NGbT1jZ",
    "outputId": "79649df5-19a7-4f4a-a2a6-f49a6cc498c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sys_setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile sys_setup.py\n",
    "#!usr/bin/bash python\n",
    "\n",
    "import sys\n",
    "from google.colab import drive\n",
    "import subprocess\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "PROJ_NAME = 'ML-Mnemonist'\n",
    "GIT_DIR = 'HamidrezaKmK'\n",
    "\n",
    "data_dir = None\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  env = os.environ.copy()\n",
    "  if not os.path.exists('/content/drive'):\n",
    "    print(\"Mounting drive...\")\n",
    "    drive.mount('/content/drive')\n",
    "    print(\"Mount complete!\")\n",
    "\n",
    "  while True:\n",
    "    opt = input(\"What are you trying to do? [clone/pull] \")\n",
    "    if opt == 'clone':\n",
    "      addr = f\"https://github.com/{GIT_DIR}/{PROJ_NAME}\"\n",
    "      print(f\"Trying to connect to {addr}\")\n",
    "      token = input(\"Enter token: \")\n",
    "      addr = addr.replace('[TOKEN]', token)\n",
    "      res = subprocess.run(['git', 'clone', addr], env=env, capture_output=True)\n",
    "      print(res.stdout.decode())\n",
    "      print(res.stderr.decode())\n",
    "      break\n",
    "    elif opt == 'pull':\n",
    "      path = os.path.join('/content', PROJ_NAME)\n",
    "      os.chdir(path)\n",
    "      res = subprocess.run(['git', 'pull'], env=env, capture_output=True)\n",
    "      print(res.stdout.decode())\n",
    "      print(res.stderr.decode())\n",
    "      break\n",
    "    elif opt == '':\n",
    "      print(\"Nothing happened!\")\n",
    "      break\n",
    "  \n",
    "  if not os.path.exists(f'/content/{PROJ_NAME}'):\n",
    "    raise RuntimeError(\"No project repository available!\")\n",
    "\n",
    "  if not os.path.exists(f'/content/{PROJ_NAME}/.env'):\n",
    "    print(\"Dotenv non-existant!\")\n",
    "    while True:\n",
    "      resp = input(\"Do you want to enter the file in the prompt or copy it?\\n[copy/write] \")\n",
    "      if resp == 'copy':\n",
    "        dir = input(\"Enter the directory to copy: \")\n",
    "        shutil.copyfile(dir, f'/content/{PROJ_NAME}/.env')\n",
    "      elif resp == 'write':\n",
    "        print(\"Enter the lines in format ENV_VARIABLE_NAME=VALUE\")\n",
    "        print(\"End with: ENDFILE\")\n",
    "        with open(f'/content/{PROJ_NAME}/.env', 'w') as f:\n",
    "          while True:\n",
    "            line = input()\n",
    "            if line == 'ENDFILE':\n",
    "              break\n",
    "            f.write(f'{line}\\n')\n",
    "      else:\n",
    "        continue\n",
    "      break\n",
    "        \n",
    "  os.chdir('/content')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "mzkBQqSLUWC3",
    "outputId": "2d475291-ff6f-430d-da51-06a1eb22bb66"
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "File `'/content/sys_setup.py'` not found.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/IPython/core/magics/execution.py:696\u001B[0m, in \u001B[0;36mExecutionMagics.run\u001B[0;34m(self, parameter_s, runner, file_finder)\u001B[0m\n\u001B[1;32m    695\u001B[0m     fpath \u001B[38;5;241m=\u001B[39m arg_lst[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m--> 696\u001B[0m     filename \u001B[38;5;241m=\u001B[39m \u001B[43mfile_finder\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfpath\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    697\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mIndexError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/IPython/utils/path.py:91\u001B[0m, in \u001B[0;36mget_py_filename\u001B[0;34m(name)\u001B[0m\n\u001B[1;32m     90\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 91\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mIOError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFile `\u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m` not found.\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m%\u001B[39m name)\n",
      "\u001B[0;31mOSError\u001B[0m: File `'/content/sys_setup.py'` not found.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mException\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [2]\u001B[0m, in \u001B[0;36m<cell line: 4>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m PROJ_NAME \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mML-Mnemonist\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mIPython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdisplay\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m clear_output\n\u001B[0;32m----> 4\u001B[0m \u001B[43mget_ipython\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_line_magic\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrun\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m/content/sys_setup.py\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28minput\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDo you want to install packages? [y/n] \u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m resp \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124my\u001B[39m\u001B[38;5;124m'\u001B[39m:\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:2305\u001B[0m, in \u001B[0;36mInteractiveShell.run_line_magic\u001B[0;34m(self, magic_name, line, _stack_depth)\u001B[0m\n\u001B[1;32m   2303\u001B[0m     kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlocal_ns\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_local_scope(stack_depth)\n\u001B[1;32m   2304\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuiltin_trap:\n\u001B[0;32m-> 2305\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2306\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/IPython/core/magics/execution.py:707\u001B[0m, in \u001B[0;36mExecutionMagics.run\u001B[0;34m(self, parameter_s, runner, file_finder)\u001B[0m\n\u001B[1;32m    705\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m os\u001B[38;5;241m.\u001B[39mname \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnt\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m re\u001B[38;5;241m.\u001B[39mmatch(\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m^\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.*\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m$\u001B[39m\u001B[38;5;124m\"\u001B[39m,fpath):\n\u001B[1;32m    706\u001B[0m         warn(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFor Windows, use double quotes to wrap a filename: \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124mun \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmypath\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mmyfile.py\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m--> 707\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(msg) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[1;32m    708\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m    709\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m fpath \u001B[38;5;129;01min\u001B[39;00m sys\u001B[38;5;241m.\u001B[39mmeta_path:\n",
      "\u001B[0;31mException\u001B[0m: File `'/content/sys_setup.py'` not found."
     ]
    }
   ],
   "source": [
    "PROJ_NAME = 'ML-Mnemonist'\n",
    "\n",
    "from IPython.display import clear_output\n",
    "%run /content/sys_setup.py\n",
    "resp = input(\"Do you want to install packages? [y/n] \")\n",
    "if resp == 'y':\n",
    "  !pip install -r /content/ML-Mnemonist/requirements.txt\n",
    "  input(\"Requrements installed! -- press any key to continue ...\")\n",
    "clear_output()\n",
    "\n",
    "import sys\n",
    "sys.path.append(f'/content/{PROJ_NAME}')\n",
    "os.chdir(f'/content/{PROJ_NAME}')\n",
    "print(\"Running complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iNiIuYQbWti3"
   },
   "source": [
    "# Expand configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_FxBXOOvtLWC"
   },
   "source": [
    "The configuration available at `conf-test-branches.yaml`\n",
    "contains multiple scenarios for the configurations to occur.\n",
    "We may expand all the possible configurations using the function below\n",
    "to create all the possible outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "azqIcguUWxka"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from mlmnemonist.validation_tools import expand_cfg\n",
    "from testing.config.config import get_cfg_defaults\n",
    "expand_cfg(get_cfg_defaults(),\n",
    "           cfg_dir='conf-test-branches.yaml',\n",
    "           save_directory='config/all-branches')\n",
    "%autoreload 3"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's create the same model we created before\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "GFRWSI6F_Af_"
   },
   "outputs": [],
   "source": [
    "from mlmnemonist.experiment_runner import ExperimentRunner\n",
    "from mlmnemonist.factory import FACTORY\n",
    "import pandas as pd\n",
    "from testing.config.config import get_cfg_defaults\n",
    "\n",
    "%autoreload 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "try:\n",
    "  runner = FACTORY.retrieve_experiment_runner('0')\n",
    "except FileNotFoundError as e:\n",
    "  runner = FACTORY.create_experiment_runner(\n",
    "    description='A sample lightweight runner',\n",
    "    cfg_base=get_cfg_defaults(),\n",
    "    experiment_name='fullsearch-runner',\n",
    "    verbose=2,\n",
    "  )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runner at /home/hamidreza/myprojects/ML-Mnemonist/testing/mnemonic-experiments/2022-07-19-fullsearch-runner-3\n",
      "\t - cache token: 0\n",
      "\t - configurations at: None\n",
      "\t - preprocessings functions []\n",
      "\t - recurring pipeline []\n",
      "\t - Run function not implemented!\n"
     ]
    }
   ],
   "source": [
    "print(runner)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "fQaHIvGQ_3YG"
   },
   "outputs": [],
   "source": [
    "runner.preprocessing_pipeline.clear_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "PhuvzGFG-86Z"
   },
   "outputs": [],
   "source": [
    "def load_raw_data(runner: ExperimentRunner):\n",
    "  train_name = runner.cfg.DATASET.TRAIN_NAME\n",
    "  test_name = runner.cfg.DATASET.TEST_NAME\n",
    "  runner.train_df = pd.read_csv(runner.reveal_true_path(train_name))\n",
    "  runner.test_df = pd.read_csv(runner.reveal_true_path(test_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "runner.preprocessing_pipeline.update_function(load_raw_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3Vo6EsKg_jmk"
   },
   "outputs": [],
   "source": [
    "def process_data(runner: ExperimentRunner):\n",
    "  runner.train_X = runner.train_df.drop(columns='median_house_value').to_numpy()\n",
    "  runner.train_Y = runner.train_df['median_house_value'].to_numpy()\n",
    "  runner.test_X = runner.test_df.drop(columns='median_house_value').to_numpy()\n",
    "  runner.test_Y = runner.test_df['median_house_value'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "runner.preprocessing_pipeline.update_function(process_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runner at /home/hamidreza/myprojects/ML-Mnemonist/testing/mnemonic-experiments/2022-07-19-fullsearch-runner-3\n",
      "\t - cache token: 0\n",
      "\t - configurations at: None\n",
      "\t - preprocessings functions ['load_raw_data', 'process_data']\n",
      "\t - recurring pipeline []\n",
      "\t - Run function not implemented!\n"
     ]
    }
   ],
   "source": [
    "print(runner)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "4rUEXYL2p-Jx"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MyMLP(nn.Module):\n",
    "    def __init__(self, input_features: int, hidden_layer_1: int, hidden_layer_2: int):\n",
    "        super(MyMLP, self).__init__()\n",
    "        self.l1 = nn.Linear(input_features, hidden_layer_1)\n",
    "        self.l2 = nn.Linear(hidden_layer_1, hidden_layer_2)\n",
    "        self.l3 = nn.Linear(hidden_layer_2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.l2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.l3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "2DdIqwaOSRlR"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "def setup_device(runner: ExperimentRunner):\n",
    "  # extract the device from config\n",
    "  device = runner.cfg.SOLVER.DEVICE\n",
    "  if device == 'cpu':\n",
    "    runner.device = torch.device('cpu')\n",
    "  elif device == 'cuda' and torch.cuda.is_available():\n",
    "    runner.device = torch.device('cuda')\n",
    "  else:\n",
    "    raise NotImplementedError(f\"device {device} is not implemented!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "runner.recurring_pipeline.update_function(setup_device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ort8OLJRIeUQ"
   },
   "outputs": [],
   "source": [
    "\n",
    "def setup_model(runner: ExperimentRunner):\n",
    "  # extract the method from config\n",
    "  method = runner.cfg.SOLVER.METHOD\n",
    "  # construct the model from registry\n",
    "  cfg_h_params = runner.cfg.MODEL.HYPER_PARAMETERS\n",
    "  my_model = MyMLP(input_features=cfg_h_params.IN_FEATURES,\n",
    "                   hidden_layer_1=cfg_h_params.H1,\n",
    "                   hidden_layer_2=cfg_h_params.H2)\n",
    "  # set the function in the cache to save weights\n",
    "  my_model = runner.CACHE.SET_M('mlp-key', my_model)\n",
    "  my_model.to(runner.device)\n",
    "  if runner.verbose > 0:\n",
    "    print(\"Model state dict\")\n",
    "    print(my_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "runner.recurring_pipeline.update_function(setup_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "sGhQ3LKcS-dC"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def setup_training(runner: ExperimentRunner):\n",
    "  my_model = runner.CACHE.GET_M('mlp-key').to(runner.device)\n",
    "  runner.criterion = nn.MSELoss()\n",
    "  if runner.cfg.SOLVER.OPTIMIZER_TYPE == 'adam':\n",
    "    runner.optim = torch.optim.Adam(my_model.parameters(), lr=runner.cfg.SOLVER.LR)\n",
    "  else:\n",
    "    raise NotImplementedError(f\"Optimizer type not implemented\"\n",
    "                              f\"{runner.cfg.SOLVER.OPTIMIZER_TYPE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "runner.recurring_pipeline.update_function(setup_training)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m3H9fjChzRRF",
    "outputId": "17f0f93e-66cd-4785-bfa7-99db66b52d8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runner at /home/hamidreza/myprojects/ML-Mnemonist/testing/mnemonic-experiments/2022-07-19-fullsearch-runner-3\n",
      "\t - cache token: 0\n",
      "\t - configurations at: None\n",
      "\t - preprocessings functions ['load_raw_data', 'process_data']\n",
      "\t - recurring pipeline ['setup_device', 'setup_model', 'setup_training']\n",
      "\t - Run function not implemented!\n"
     ]
    }
   ],
   "source": [
    "print(runner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57mO42YpH-Ck"
   },
   "source": [
    "# Implement a run function\n",
    "\n",
    "A run function is the core part of an experiment. This function takes in an input of type `ExperimentRunner` type is its first element and a bunch of arbitrary input types for the rest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ajq3MZ0bhlxG",
    "outputId": "05c1c2ab-bf36-49b1-9cda-c9f1ff1f8abc"
   },
   "outputs": [],
   "source": [
    "runner.CACHE.RESET()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "0il8pIX8H_uz"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "def helper(model, X, y, history, device, loss_fn, optimizer=None):\n",
    "  for st in range(0, X.shape[0], 500):\n",
    "    en = min(st + 500, X.shape[0])\n",
    "    X_ = torch.from_numpy(X[st:en, :]).float().to(device)\n",
    "    pred = model(X_)\n",
    "    y_ = torch.from_numpy(y[st:en]).float().to(device)\n",
    "    loss = loss_fn(pred.squeeze(), y_)\n",
    "    if optimizer is not None:\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "    history.append(loss.detach().cpu().item())\n",
    "    \n",
    "def my_custom_run(runner: ExperimentRunner, show_freq=5):\n",
    "  # print(runner.CACHE._cached_primitives)\n",
    "  # return\n",
    "  # Get model from cache\n",
    "  my_model = runner.CACHE.GET_M('mlp-key')\n",
    "\n",
    "  # Get the epoch number and history from cache\n",
    "  # if it is not cached from before set it to zero\n",
    "  epoch_i = runner.CACHE.SET_IFN('epoch_i', 0)\n",
    "  loss_history = runner.CACHE.SET_IFN('loss-history', [[], []])\n",
    "  writer = SummaryWriter(log_dir=runner.CACHE.LOGS_DIR)\n",
    "  inds = np.arange(runner.train_X.shape[0])\n",
    "  for epoch_i in range(epoch_i, 100):\n",
    "\n",
    "    np.random.shuffle(inds)\n",
    "\n",
    "    loss_train = []\n",
    "    my_model.train()\n",
    "    helper(my_model, runner.train_X[inds],\n",
    "           runner.train_Y[inds], loss_train, runner.device,\n",
    "           runner.criterion, runner.optim)\n",
    "    mean_loss = sum(loss_train) / len(loss_train)\n",
    "    loss_history[0].append(mean_loss)\n",
    "    train_loss = mean_loss\n",
    "    loss_test = []\n",
    "    my_model.eval()\n",
    "    with torch.no_grad():\n",
    "      helper(my_model, runner.test_X,\n",
    "            runner.test_Y, loss_test, runner.device,\n",
    "            runner.criterion)\n",
    "    mean_loss = sum(loss_test) / len(loss_test)\n",
    "    loss_history[1].append(mean_loss)\n",
    "    test_loss = mean_loss\n",
    "    writer.add_scalars('losses', {\n",
    "      'train': train_loss,\n",
    "      'test': test_loss\n",
    "    }, epoch_i)\n",
    "    if (epoch_i + 1) % show_freq == 0:\n",
    "      if runner.verbose > 0:\n",
    "        clear_output()\n",
    "        plt.plot(list(range(len(loss_history[0]))), loss_history[0], label='loss-train')\n",
    "        plt.plot(list(range(len(loss_history[1]))), loss_history[1], label='loss-test')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    # Caching and saving checkpoints\n",
    "    runner.CACHE.SET('epoch_i', epoch_i)\n",
    "    runner.CACHE.SET('loss-history', loss_history)\n",
    "    runner.CACHE.SET_M('mlp-key', my_model)\n",
    "    runner.CACHE.SAVE()\n",
    "\n",
    "  return loss_history[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "runner.implement_run(my_custom_run)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create a hyperrunner"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "hyper_runner = FACTORY.create_hyper_experiment_runner(\n",
    "  experiment_name='cross-run',\n",
    "  cfg_base=get_cfg_defaults(),\n",
    "  cfg_palette_path='conf-test-branches.yaml',\n",
    "  experiment_runners=[runner],\n",
    "  verbose=4,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cc8aGQq_jDAG"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<mlmnemonist.validation_tools.hyper_experiment_runner.HyperExperimentRunner object at 0x7f6985dbc940>\n"
     ]
    }
   ],
   "source": [
    "print(hyper_runner)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ixAXNzv72XdZ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hyper_runner.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamidreza/myprojects/ML-Mnemonist/mlmnemonist/validation_tools/hyper_experiment_runner.py:87: UserWarning: Exception caught \n",
      "  warnings.warn(f\"Exception caught {e}\")\n"
     ]
    }
   ],
   "source": [
    "hyper_runner.full_search(\n",
    "  exception_list=(KeyboardInterrupt),\n",
    "  with_preprocess=True\n",
    ")\n",
    "\n",
    "%autoreload 3\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "ExperimentRunnerTutorial.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}