{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/HamidrezaKmK/ML-Mnemonist/blob/main/ExperimentRunnerTutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rE6olttuFV0Q"
   },
   "source": [
    "# Setup hosted runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eOfp_NGbT1jZ",
    "outputId": "79649df5-19a7-4f4a-a2a6-f49a6cc498c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing sys_setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile sys_setup.py\n",
    "#!usr/bin/bash python\n",
    "\n",
    "import sys\n",
    "from google.colab import drive\n",
    "import subprocess\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "PROJ_NAME = 'ML-Mnemonist'\n",
    "GIT_DIR = 'HamidrezaKmK'\n",
    "\n",
    "data_dir = None\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  env = os.environ.copy()\n",
    "  if not os.path.exists('/content/drive'):\n",
    "    print(\"Mounting drive...\")\n",
    "    drive.mount('/content/drive')\n",
    "    print(\"Mount complete!\")\n",
    "\n",
    "  while True:\n",
    "    opt = input(\"What are you trying to do? [clone/pull] \")\n",
    "    if opt == 'clone':\n",
    "      addr = f\"https://github.com/{GIT_DIR}/{PROJ_NAME}\"\n",
    "      print(f\"Trying to connect to {addr}\")\n",
    "      token = input(\"Enter token: \")\n",
    "      addr = addr.replace('[TOKEN]', token)\n",
    "      res = subprocess.run(['git', 'clone', addr], env=env, capture_output=True)\n",
    "      print(res.stdout.decode())\n",
    "      print(res.stderr.decode())\n",
    "      break\n",
    "    elif opt == 'pull':\n",
    "      path = os.path.join('/content', PROJ_NAME)\n",
    "      os.chdir(path)\n",
    "      res = subprocess.run(['git', 'pull'], env=env, capture_output=True)\n",
    "      print(res.stdout.decode())\n",
    "      print(res.stderr.decode())\n",
    "      break\n",
    "    elif opt == '':\n",
    "      print(\"Nothing happened!\")\n",
    "      break\n",
    "  \n",
    "  if not os.path.exists(f'/content/{PROJ_NAME}'):\n",
    "    raise RuntimeError(\"No project repository available!\")\n",
    "\n",
    "  if not os.path.exists(f'/content/{PROJ_NAME}/.env'):\n",
    "    print(\"Dotenv non-existant!\")\n",
    "    while True:\n",
    "      resp = input(\"Do you want to enter the file in the prompt or copy it?\\n[copy/write] \")\n",
    "      if resp == 'copy':\n",
    "        dir = input(\"Enter the directory to copy: \")\n",
    "        shutil.copyfile(dir, f'/content/{PROJ_NAME}/.env')\n",
    "      elif resp == 'write':\n",
    "        print(\"Enter the lines in format ENV_VARIABLE_NAME=VALUE\")\n",
    "        print(\"End with: ENDFILE\")\n",
    "        with open(f'/content/{PROJ_NAME}/.env', 'w') as f:\n",
    "          while True:\n",
    "            line = input()\n",
    "            if line == 'ENDFILE':\n",
    "              break\n",
    "            f.write(f'{line}\\n')\n",
    "      else:\n",
    "        continue\n",
    "      break\n",
    "        \n",
    "  os.chdir('/content')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "mzkBQqSLUWC3",
    "outputId": "2d475291-ff6f-430d-da51-06a1eb22bb66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running complete!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PROJ_NAME = 'ML-Mnemonist'\n",
    "\n",
    "from IPython.display import clear_output\n",
    "%run /content/sys_setup.py\n",
    "resp = input(\"Do you want to install packages? [y/n] \")\n",
    "if resp == 'y':\n",
    "  !pip install -r /content/ML-Mnemonist/requirements.txt\n",
    "  input(\"Requrements installed! -- press any key to continue ...\")\n",
    "clear_output()\n",
    "\n",
    "import sys\n",
    "sys.path.append(f'/content/{PROJ_NAME}')\n",
    "os.chdir(f'/content/{PROJ_NAME}')\n",
    "print(\"Running complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iNiIuYQbWti3"
   },
   "source": [
    "# Experiment runner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_FxBXOOvtLWC"
   },
   "source": [
    "Create a runner factory. This factory has the ability to create your runners. The factory automatically fills up the environment variables using the `.env` file provided. \n",
    "\n",
    "It fills up the following:\n",
    "- `config_dir`: A path containing all your configuration `yaml` files.\n",
    "- `experiment_dir`: A path containing all your experiments. The result of all the experiments will be stored as directories in this path.\n",
    "- `checkpoint_dir`: A path containing all the model checkpoints which is used for cached run functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "azqIcguUWxka"
   },
   "outputs": [],
   "source": [
    "from mlmnemonist.experiment_factory import ExperimentRunnerFactory\n",
    "from config.config import get_cfg_defaults\n",
    "\n",
    "factory = ExperimentRunnerFactory(config_default_builder=get_cfg_defaults)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "2Eh4tGm5XTOR"
   },
   "outputs": [],
   "source": [
    "token = None\n",
    "token = '1-tok' \n",
    "runner = factory.create(cfg_dir='conf-test.yaml', experiment_name='my_first_experiment', \n",
    "                        verbose=1, cache_token=token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hq7nSM-f8ehy",
    "outputId": "01b07a97-a5c5-414c-f84d-9fc60fabd313"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment runner of type: <class 'mlmnemonist.experiment_runner.ExperimentRunner'>\n",
      "\t - cache token: 1-tok\n",
      "\t - configurations at: ./config/conf-test.yaml\n",
      "\t - preprocessings functions []\n",
      "\t - recurring pipeline []\n",
      "\t - Run function not implemented!\n"
     ]
    }
   ],
   "source": [
    "print(runner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U_PEvAX89xMs"
   },
   "source": [
    "# Run a simple linear regression program\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "GFRWSI6F_Af_"
   },
   "outputs": [],
   "source": [
    "from mlmnemonist.experiment_runner import ExperimentRunner\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "fQaHIvGQ_3YG"
   },
   "outputs": [],
   "source": [
    "runner.preprocessing_pipeline.clear_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "PhuvzGFG-86Z"
   },
   "outputs": [],
   "source": [
    "def load_raw_data(runner: ExperimentRunner):\n",
    "  train_name = runner.cfg.DATASET.TRAIN_NAME\n",
    "  test_name = runner.cfg.DATASET.TEST_NAME\n",
    "  runner.train_df = pd.read_csv(runner.reveal_true_path(train_name))\n",
    "  runner.test_df = pd.read_csv(runner.reveal_true_path(test_name))\n",
    "runner.preprocessing_pipeline.update_function(load_raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3Vo6EsKg_jmk"
   },
   "outputs": [],
   "source": [
    "def process_data(runner: ExperimentRunner):\n",
    "  runner.train_X = runner.train_df.drop(columns='median_house_value').to_numpy()\n",
    "  runner.train_Y = runner.train_df['median_house_value'].to_numpy()\n",
    "  runner.test_X = runner.test_df.drop(columns='median_house_value').to_numpy()\n",
    "  runner.test_Y = runner.test_df['median_house_value'].to_numpy()\n",
    "runner.preprocessing_pipeline.update_function(process_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PuGBf7CgAuwB",
    "outputId": "b74da402-4d9c-4e49-f3d1-6217f65b0230"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment runner of type: <class 'mlmnemonist.experiment_runner.ExperimentRunner'>\n",
      "\t - cache token: 1-tok\n",
      "\t - configurations at: ./config/conf-test.yaml\n",
      "\t - preprocessings functions ['load_raw_data', 'process_data']\n",
      "\t - recurring pipeline []\n",
      "\t - Run function not implemented!\n"
     ]
    }
   ],
   "source": [
    "print(runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o9XySh8pBGwz",
    "outputId": "279a1b1d-764f-4e9b-a8c5-a53d936e709e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No functions in the preprocessing pipeline!\n"
     ]
    }
   ],
   "source": [
    "# Run the functions in line\n",
    "runner.preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dXriKjd6IaYC"
   },
   "source": [
    "## Create a model\n",
    "\n",
    "All models are stored in the `src.modeling` directory. Each modeling file should contain a registry that will give us access to different model types using a configuration. \n",
    "\n",
    "For example, in `conf-test.yaml` we defined an MLP with 3 layers and certain hyper parameters. The following functions are part of preprocessing and setup our model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "4rUEXYL2p-Jx"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MyMLP(nn.Module):\n",
    "    def __init__(self, input_features: int, hidden_layer_1: int, hidden_layer_2: int):\n",
    "        super(MyMLP, self).__init__()\n",
    "        self.l1 = nn.Linear(input_features, hidden_layer_1)\n",
    "        self.l2 = nn.Linear(hidden_layer_1, hidden_layer_2)\n",
    "        self.l3 = nn.Linear(hidden_layer_2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.l2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.l3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "2DdIqwaOSRlR"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "def setup_device(runner: ExperimentRunner):\n",
    "  # extract the device from config\n",
    "  device = runner.cfg.SOLVER.DEVICE\n",
    "  if device == 'cpu':\n",
    "    runner.device = torch.device('cpu')\n",
    "  elif device == 'cuda' and torch.cuda.is_available():\n",
    "    runner.device = torch.device('cuda')\n",
    "  else:\n",
    "    raise NotImplementedError(f\"device {device} is not implemented!\")\n",
    "runner.recurring_pipeline.update_function(setup_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ort8OLJRIeUQ"
   },
   "outputs": [],
   "source": [
    "\n",
    "def setup_model(runner: ExperimentRunner):\n",
    "  # extract the method from config\n",
    "  method = runner.cfg.SOLVER.METHOD\n",
    "  # construct the model from registry\n",
    "  cfg_h_params = runner.cfg.MODEL.HYPER_PARAMETERS\n",
    "  my_model = MyMLP(input_features=cfg_h_params.IN_FEATURES,\n",
    "                   hidden_layer_1=cfg_h_params.H1,\n",
    "                   hidden_layer_2=cfg_h_params.H2)\n",
    "  # set the function in the cache to save weights\n",
    "  my_model = runner.CACHE.SET_M('mlp-key', my_model)\n",
    "  my_model.to(runner.device)\n",
    "  if runner.verbose > 0:\n",
    "    print(\"Model state dict\")\n",
    "    print(my_model)\n",
    "runner.recurring_pipeline.update_function(setup_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "sGhQ3LKcS-dC"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def setup_training(runner: ExperimentRunner):\n",
    "  my_model = runner.CACHE.GET_M('mlp-key').to(runner.device)\n",
    "  runner.criterion = nn.MSELoss()\n",
    "  if runner.cfg.SOLVER.OPTIMIZER_TYPE == 'adam':\n",
    "    runner.optim = torch.optim.Adam(my_model.parameters(), lr=runner.cfg.SOLVER.LR)\n",
    "  else:\n",
    "    raise NotImplementedError(f\"Optimizer type not implemented\"\n",
    "                              f\"{runner.cfg.SOLVER.OPTIMIZER_TYPE}\")\n",
    "runner.recurring_pipeline.update_function(setup_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m3H9fjChzRRF",
    "outputId": "17f0f93e-66cd-4785-bfa7-99db66b52d8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment runner of type: <class 'mlmnemonist.experiment_runner.ExperimentRunner'>\n",
      "\t - cache token: 1-tok\n",
      "\t - configurations at: ./config/conf-test.yaml\n",
      "\t - preprocessings functions []\n",
      "\t - recurring pipeline ['setup_device', 'setup_model', 'setup_training']\n",
      "\t - Run function not implemented!\n"
     ]
    }
   ],
   "source": [
    "print(runner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57mO42YpH-Ck"
   },
   "source": [
    "# Implement a run function\n",
    "\n",
    "A run function is the core part of an experiment. This function takes in an input of type `ExperimentRunner` type is its first element and a bunch of arbitrary input types for the rest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ajq3MZ0bhlxG",
    "outputId": "05c1c2ab-bf36-49b1-9cda-c9f1ff1f8abc"
   },
   "outputs": [],
   "source": [
    "runner.CACHE.RESET()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "0il8pIX8H_uz"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "def helper(model, X, y, history, device, loss_fn, optimizer=None):\n",
    "  for st in range(0, X.shape[0], 500):\n",
    "    en = min(st + 500, X.shape[0])\n",
    "    X_ = torch.from_numpy(X[st:en, :]).float().to(device)\n",
    "    pred = model(X_)\n",
    "    y_ = torch.from_numpy(y[st:en]).float().to(device)\n",
    "    loss = loss_fn(pred.squeeze(), y_)\n",
    "    if optimizer is not None:\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "    history.append(loss.detach().cpu().item())\n",
    "    \n",
    "def my_custom_run(runner: ExperimentRunner, show_freq=50):\n",
    "  # print(runner.CACHE._cached_primitives)\n",
    "  # return\n",
    "  # Get model from cache\n",
    "  my_model = runner.CACHE.GET_M('mlp-key')\n",
    "\n",
    "  # Get the epoch number and history from cache\n",
    "  # if it is not cached from before set it to zero\n",
    "  epoch_i = runner.CACHE.SET_IFN('epoch_i', 0)\n",
    "  loss_history = runner.CACHE.SET_IFN('loss-history', [[], []])\n",
    "  writer = SummaryWriter(log_dir=runner.CACHE.LOGS_DIR)\n",
    "  for epoch_i in range(epoch_i, 10000):\n",
    "\n",
    "    inds = np.arange(runner.train_X.shape[0])\n",
    "    np.random.shuffle(inds)\n",
    "\n",
    "    loss_train = []\n",
    "    my_model.train()\n",
    "    helper(my_model, runner.train_X[inds],\n",
    "           runner.train_Y[inds], loss_train, runner.device,\n",
    "           runner.criterion, runner.optim)\n",
    "    mean_loss = sum(loss_train) / len(loss_train)\n",
    "    loss_history[0].append(mean_loss)\n",
    "    train_loss = mean_loss\n",
    "    loss_test = []\n",
    "    my_model.eval()\n",
    "    with torch.no_grad():\n",
    "      helper(my_model, runner.test_X,\n",
    "            runner.test_Y, loss_test, runner.device,\n",
    "            runner.criterion)\n",
    "    mean_loss = sum(loss_test) / len(loss_test)\n",
    "    loss_history[1].append(mean_loss)\n",
    "    test_loss = mean_loss\n",
    "    writer.add_scalars('losses', {\n",
    "      'train': train_loss,\n",
    "      'test': test_loss\n",
    "    }, epoch_i)\n",
    "    if (epoch_i + 1) % show_freq == 0:\n",
    "      clear_output()\n",
    "      plt.plot(list(range(len(loss_history[0]))), loss_history[0], label='loss-train')\n",
    "      plt.plot(list(range(len(loss_history[1]))), loss_history[1], label='loss-test')\n",
    "      plt.legend()\n",
    "      plt.show()\n",
    "\n",
    "    # Caching and saving checkpoints\n",
    "    runner.CACHE.SET('epoch_i', epoch_i)\n",
    "    runner.CACHE.SET('loss-history', loss_history)\n",
    "    runner.CACHE.SET_M('mlp-key', my_model)\n",
    "    runner.CACHE.SAVE()\n",
    "\n",
    "runner.implement_run(my_custom_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cc8aGQq_jDAG"
   },
   "source": [
    "Run the following function to see the training and validation loss.\n",
    "Interrupt the process for as many times as you like and re-run it. Since the code supports caching, it will continue right off where it last ended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ixAXNzv72XdZ"
   },
   "outputs": [],
   "source": [
    "del runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "p6IKYVw7dKBo",
    "outputId": "a3436114-2c4a-4dc5-a453-c82cb8b413eb"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [18]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mrunner\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mshow_freq\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/myprojects/ML-Mnemonist/mlmnemonist/experiment_runner.py:151\u001B[0m, in \u001B[0;36mExperimentRunner.run\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrecurring_pipeline\u001B[38;5;241m.\u001B[39mrun(keep\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose, runner\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m    150\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mCACHE\u001B[38;5;241m.\u001B[39m_load_cache()\n\u001B[0;32m--> 151\u001B[0m ret \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_implemented_run\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    153\u001B[0m \u001B[38;5;66;03m# Save files\u001B[39;00m\n\u001B[1;32m    154\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "Input \u001B[0;32mIn [17]\u001B[0m, in \u001B[0;36mmy_custom_run\u001B[0;34m(runner, show_freq)\u001B[0m\n\u001B[1;32m     59\u001B[0m   plt\u001B[38;5;241m.\u001B[39mplot(\u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(loss_history[\u001B[38;5;241m1\u001B[39m]))), loss_history[\u001B[38;5;241m1\u001B[39m], label\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mloss-test\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     60\u001B[0m   plt\u001B[38;5;241m.\u001B[39mlegend()\n\u001B[0;32m---> 61\u001B[0m   \u001B[43mplt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshow\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;66;03m# Caching and saving checkpoints\u001B[39;00m\n\u001B[1;32m     64\u001B[0m runner\u001B[38;5;241m.\u001B[39mCACHE\u001B[38;5;241m.\u001B[39mSET(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mepoch_i\u001B[39m\u001B[38;5;124m'\u001B[39m, epoch_i)\n",
      "File \u001B[0;32m/usr/lib/python3/dist-packages/matplotlib/pyplot.py:269\u001B[0m, in \u001B[0;36mshow\u001B[0;34m(*args, **kw)\u001B[0m\n\u001B[1;32m    252\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    253\u001B[0m \u001B[38;5;124;03mDisplay a figure.\u001B[39;00m\n\u001B[1;32m    254\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    266\u001B[0m \u001B[38;5;124;03mdescribed above.\u001B[39;00m\n\u001B[1;32m    267\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    268\u001B[0m \u001B[38;5;28;01mglobal\u001B[39;00m _show\n\u001B[0;32m--> 269\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_show\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkw\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/matplotlib_inline/backend_inline.py:41\u001B[0m, in \u001B[0;36mshow\u001B[0;34m(close, block)\u001B[0m\n\u001B[1;32m     39\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     40\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m figure_manager \u001B[38;5;129;01min\u001B[39;00m Gcf\u001B[38;5;241m.\u001B[39mget_all_fig_managers():\n\u001B[0;32m---> 41\u001B[0m         \u001B[43mdisplay\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     42\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfigure_manager\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcanvas\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfigure\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     43\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_fetch_figure_metadata\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfigure_manager\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcanvas\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfigure\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     44\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     45\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     46\u001B[0m     show\u001B[38;5;241m.\u001B[39m_to_draw \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/IPython/core/display_functions.py:298\u001B[0m, in \u001B[0;36mdisplay\u001B[0;34m(include, exclude, metadata, transient, display_id, raw, clear, *objs, **kwargs)\u001B[0m\n\u001B[1;32m    296\u001B[0m     publish_display_data(data\u001B[38;5;241m=\u001B[39mobj, metadata\u001B[38;5;241m=\u001B[39mmetadata, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    297\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 298\u001B[0m     format_dict, md_dict \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mformat\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minclude\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minclude\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexclude\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexclude\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    299\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m format_dict:\n\u001B[1;32m    300\u001B[0m         \u001B[38;5;66;03m# nothing to display (e.g. _ipython_display_ took over)\u001B[39;00m\n\u001B[1;32m    301\u001B[0m         \u001B[38;5;28;01mcontinue\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/IPython/core/formatters.py:178\u001B[0m, in \u001B[0;36mDisplayFormatter.format\u001B[0;34m(self, obj, include, exclude)\u001B[0m\n\u001B[1;32m    176\u001B[0m md \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    177\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 178\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[43mformatter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    179\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[1;32m    180\u001B[0m     \u001B[38;5;66;03m# FIXME: log the exception\u001B[39;00m\n\u001B[1;32m    181\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/decorator.py:232\u001B[0m, in \u001B[0;36mdecorate.<locals>.fun\u001B[0;34m(*args, **kw)\u001B[0m\n\u001B[1;32m    230\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m kwsyntax:\n\u001B[1;32m    231\u001B[0m     args, kw \u001B[38;5;241m=\u001B[39m fix(args, kw, sig)\n\u001B[0;32m--> 232\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcaller\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mextras\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkw\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/IPython/core/formatters.py:222\u001B[0m, in \u001B[0;36mcatch_format_error\u001B[0;34m(method, self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    220\u001B[0m \u001B[38;5;124;03m\"\"\"show traceback on failed format call\"\"\"\u001B[39;00m\n\u001B[1;32m    221\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 222\u001B[0m     r \u001B[38;5;241m=\u001B[39m \u001B[43mmethod\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    223\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m:\n\u001B[1;32m    224\u001B[0m     \u001B[38;5;66;03m# don't warn on NotImplementedErrors\u001B[39;00m\n\u001B[1;32m    225\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_return(\u001B[38;5;28;01mNone\u001B[39;00m, args[\u001B[38;5;241m0\u001B[39m])\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/IPython/core/formatters.py:339\u001B[0m, in \u001B[0;36mBaseFormatter.__call__\u001B[0;34m(self, obj)\u001B[0m\n\u001B[1;32m    337\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[1;32m    338\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 339\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mprinter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    340\u001B[0m \u001B[38;5;66;03m# Finally look for special method names\u001B[39;00m\n\u001B[1;32m    341\u001B[0m method \u001B[38;5;241m=\u001B[39m get_real_method(obj, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprint_method)\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/IPython/core/pylabtools.py:151\u001B[0m, in \u001B[0;36mprint_figure\u001B[0;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend_bases\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m FigureCanvasBase\n\u001B[1;32m    149\u001B[0m     FigureCanvasBase(fig)\n\u001B[0;32m--> 151\u001B[0m \u001B[43mfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcanvas\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprint_figure\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbytes_io\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkw\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    152\u001B[0m data \u001B[38;5;241m=\u001B[39m bytes_io\u001B[38;5;241m.\u001B[39mgetvalue()\n\u001B[1;32m    153\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m fmt \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msvg\u001B[39m\u001B[38;5;124m'\u001B[39m:\n",
      "File \u001B[0;32m/usr/lib/python3/dist-packages/matplotlib/backend_bases.py:2066\u001B[0m, in \u001B[0;36mFigureCanvasBase.print_figure\u001B[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001B[0m\n\u001B[1;32m   2064\u001B[0m renderer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfigure\u001B[38;5;241m.\u001B[39m_cachedRenderer\n\u001B[1;32m   2065\u001B[0m bbox_artists \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbbox_extra_artists\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m-> 2066\u001B[0m bbox_inches \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfigure\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_tightbbox\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrenderer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2067\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbbox_extra_artists\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbbox_artists\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2068\u001B[0m pad \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpad_inches\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m   2069\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m pad \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m/usr/lib/python3/dist-packages/matplotlib/figure.py:2367\u001B[0m, in \u001B[0;36mFigure.get_tightbbox\u001B[0;34m(self, renderer, bbox_extra_artists)\u001B[0m\n\u001B[1;32m   2364\u001B[0m     artists \u001B[38;5;241m=\u001B[39m bbox_extra_artists\n\u001B[1;32m   2366\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m a \u001B[38;5;129;01min\u001B[39;00m artists:\n\u001B[0;32m-> 2367\u001B[0m     bbox \u001B[38;5;241m=\u001B[39m \u001B[43ma\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_tightbbox\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrenderer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2368\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m bbox \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m (bbox\u001B[38;5;241m.\u001B[39mwidth \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m bbox\u001B[38;5;241m.\u001B[39mheight \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m):\n\u001B[1;32m   2369\u001B[0m         bb\u001B[38;5;241m.\u001B[39mappend(bbox)\n",
      "File \u001B[0;32m/usr/lib/python3/dist-packages/matplotlib/axes/_base.py:4357\u001B[0m, in \u001B[0;36m_AxesBase.get_tightbbox\u001B[0;34m(self, renderer, call_axes_locator, bbox_extra_artists)\u001B[0m\n\u001B[1;32m   4354\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_aspect()\n\u001B[1;32m   4356\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maxison:\n\u001B[0;32m-> 4357\u001B[0m     bb_xaxis \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mxaxis\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_tightbbox\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrenderer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4358\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m bb_xaxis:\n\u001B[1;32m   4359\u001B[0m         bb\u001B[38;5;241m.\u001B[39mappend(bb_xaxis)\n",
      "File \u001B[0;32m/usr/lib/python3/dist-packages/matplotlib/axis.py:1162\u001B[0m, in \u001B[0;36mAxis.get_tightbbox\u001B[0;34m(self, renderer)\u001B[0m\n\u001B[1;32m   1159\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_visible():\n\u001B[1;32m   1160\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[0;32m-> 1162\u001B[0m ticks_to_draw \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_update_ticks\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1164\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_label_position(renderer)\n\u001B[1;32m   1166\u001B[0m \u001B[38;5;66;03m# go back to just this axis's tick labels\u001B[39;00m\n",
      "File \u001B[0;32m/usr/lib/python3/dist-packages/matplotlib/axis.py:1080\u001B[0m, in \u001B[0;36mAxis._update_ticks\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1075\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1076\u001B[0m \u001B[38;5;124;03mUpdate ticks (position and labels) using the current data interval of\u001B[39;00m\n\u001B[1;32m   1077\u001B[0m \u001B[38;5;124;03mthe axes.  Return the list of ticks that will be drawn.\u001B[39;00m\n\u001B[1;32m   1078\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1079\u001B[0m major_locs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_majorticklocs()\n\u001B[0;32m-> 1080\u001B[0m major_labels \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmajor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mformatter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mformat_ticks\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmajor_locs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1081\u001B[0m major_ticks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_major_ticks(\u001B[38;5;28mlen\u001B[39m(major_locs))\n\u001B[1;32m   1082\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmajor\u001B[38;5;241m.\u001B[39mformatter\u001B[38;5;241m.\u001B[39mset_locs(major_locs)\n",
      "File \u001B[0;32m/usr/lib/python3/dist-packages/matplotlib/ticker.py:259\u001B[0m, in \u001B[0;36mFormatter.format_ticks\u001B[0;34m(self, values)\u001B[0m\n\u001B[1;32m    257\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mformat_ticks\u001B[39m(\u001B[38;5;28mself\u001B[39m, values):\n\u001B[1;32m    258\u001B[0m     \u001B[38;5;124;03m\"\"\"Return the tick labels for all the ticks at once.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 259\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset_locs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    260\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[38;5;28mself\u001B[39m(value, i) \u001B[38;5;28;01mfor\u001B[39;00m i, value \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(values)]\n",
      "File \u001B[0;32m/usr/lib/python3/dist-packages/matplotlib/ticker.py:687\u001B[0m, in \u001B[0;36mScalarFormatter.set_locs\u001B[0;34m(self, locs)\u001B[0m\n\u001B[1;32m    685\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlocs) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    686\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_useOffset:\n\u001B[0;32m--> 687\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_compute_offset\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    688\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_set_order_of_magnitude()\n\u001B[1;32m    689\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_set_format()\n",
      "File \u001B[0;32m/usr/lib/python3/dist-packages/matplotlib/ticker.py:694\u001B[0m, in \u001B[0;36mScalarFormatter._compute_offset\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    692\u001B[0m locs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlocs\n\u001B[1;32m    693\u001B[0m \u001B[38;5;66;03m# Restrict to visible ticks.\u001B[39;00m\n\u001B[0;32m--> 694\u001B[0m vmin, vmax \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43msorted\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_view_interval\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    695\u001B[0m locs \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(locs)\n\u001B[1;32m    696\u001B[0m locs \u001B[38;5;241m=\u001B[39m locs[(vmin \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m locs) \u001B[38;5;241m&\u001B[39m (locs \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m vmax)]\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "runner.run(show_freq=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Export tensorboard logs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files being archived in ./mnemonic-experiments/my_first_experiment/logs-export.zip ...\n"
     ]
    },
    {
     "data": {
      "text/plain": "'./mnemonic-experiments/my_first_experiment/logs-export.zip'"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runner.export_logs()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-AqjwHsjpML"
   },
   "source": [
    "# Run even after the session is closed\n",
    "\n",
    "Each runner has a cache token associated with it. You can checkout your runner's token using the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "OSKZn4j_jrmH",
    "outputId": "1dcbf48e-5a07-4b5f-db50-17d2e614723f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'1-tok'"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runner.CACHE.TOKEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M6sVSjy_j5hh"
   },
   "source": [
    "Now re-run your session and when you are creating a runner use the token in the `cache_token=YOUR_TOKEN` variable. That way, when you call `load_cache()` or whenever you re-run the `run()` function. All the variables that have been cached will be reloaded again."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "ExperimentRunnerTutorial.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}